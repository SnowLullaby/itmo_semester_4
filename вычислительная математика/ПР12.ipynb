{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ab461380",
      "metadata": {
        "id": "ab461380"
      },
      "source": [
        "# Практическая работа 12: Исследование работы LLM в контексте работы с собственными числами матрицы"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4218c1a",
      "metadata": {
        "id": "c4218c1a"
      },
      "source": [
        "Ваше ФИО:\n",
        "\n",
        "Вавилина Екатерина Андреевна"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9cde448",
      "metadata": {
        "id": "f9cde448"
      },
      "source": [
        "Что хотим сегодня изучить:\n",
        "1. Реализации методов поиска собственных значений и собственных векторов на Python\n",
        "2. Метод главных компонент, который много где используется сам по себе и основан на работе с собственными значениями матриц\n",
        "3. Метод главных компонент для оптимизации (уменьшения размеров) модели LLM\n",
        "4. Общение с AI-ассистентами (готовыми LLM) для исследования (изучения) новой предметной области (пункт 3 из списка ниже)\n",
        "5. Научиться писать промпты к LLM так, чтобы получать адекватные и неадекватные результаты (галлюцинации)\n",
        "6. Находить и устранять галлюцинации LLM в программировании и исследовании, когда предметная область Вам уже знакома (пункт 2 из списка ниже)\n",
        "7. Научиться оптимизировать модели LLM и проверять их точность (пункт 1 из списка ниже)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d3f4964",
      "metadata": {
        "id": "4d3f4964"
      },
      "source": [
        "В контексте использования large language model (LLM) термин \"исследование\" обычно относится к процессу изучения, разработки или применения LLM для достижения научных, технических или академических целей. Он может иметь несколько значений в зависимости от конкретного контекста:\n",
        "\n",
        "1. **Разработка модели**: Исследование включает в себя создание или совершенствование LLM, включая проектирование архитектуры, оптимизацию алгоритмов обучения или повышение производительности (например, точности, результативности или обобщения). Этим часто занимаются исследователи ИИ или инженеры.\n",
        "\n",
        "2. **Изучение возможностей**: Исследование может означать изучение того, что могут делать LLM, например, тестирование их способности решать конкретные задачи (например, понимать естественный язык, рассуждать или генерировать код) или оценку их ограничений и предубеждений.\n",
        "\n",
        "3. **Применение к предметной области**: Использование LLMS для поддержки исследований в других областях, таких как анализ научной литературы, генерация гипотез или автоматизация обработки данных в таких дисциплинах, как медицина, физика или социальные науки.\n",
        "\n",
        "4. **Влияние на этику и общество**: Изучение последствий внедрения LLM, включая справедливость, безопасность, риски дезинформации или экологические издержки, связанные с обучением и выводами.\n",
        "\n",
        "Например, исследователь может использовать LLM для анализа обширных наборов данных для исследования (прикладной работы) или для экспериментов с тонкой настройкой, чтобы улучшить производительность при выполнении узкоспециализированной задачи (разработка). Термин является широким, но обычно подразумевает систематическое изучение или экспериментирование с участием LLM."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3edbe6b7",
      "metadata": {
        "id": "3edbe6b7"
      },
      "source": [
        "### **План работы (разделы ноутбука)**\n",
        "1. Выбрать один или несколько AI-ассистентов из списка ниже и перечислить их ниже.\n",
        "2. Написать промпт (желательно один, чтобы можно было корректнее сравнить результат) на любой языке, на котором Вы ожидаете получить лучший результат, в результате которого выбрать модель с весами LLM для скачивания. Далее будем работать с этой моделью как с матрицей. Сравните ответы полученные от разных LLM в таблице.\n",
        "3. После этого с помощью того же или нового набора AI-ассистентов, получите сниппет для скачивания и начала работы с моделью. Вставьте сниппеты в соответствующие ячейки. Запустите ячейки и сравните полученные результаты, не внося дополнительных изменений в код, если он не работает.\n",
        "4. Если код после запуска не работает, получите у соответствующего AI-ассистента рекомендации по исправлению кода. Вставьте исправленный код в новую соответствующую ячейку. Запустите код и в случае, если код снова не работает, получите новые исправления. Продолжайте либо, пока код не заработает, либо пока AI-ассистент не начнёт слишком сильно галлюцинировать. Протоколируйте все диалоги в соответствующие ячейки. Проведите анализ полученных результатов в текущем разделе.\n",
        "5. Напишите собственные реализации методов нахождения собственных чисел и собственных векторов матриц, используя вызовы готовых реализаций в стандартных библиотеках или подробные описания.\n",
        "6. Заставьте AI-агентов написать сниппеты для тех же методов. Сравните на любой матрце.\n",
        "7. Исследуйте метод главных компонент для оптимизации размера выбранной модели при помощи собственных значений и собственных векторов. Сравните результаты работы модели до и после оптимизации.\n",
        "8. Заключение."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49d76d05",
      "metadata": {
        "id": "49d76d05"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50db8ee5",
      "metadata": {
        "id": "50db8ee5"
      },
      "source": [
        "## Раздел 1. Выбрать один или несколько AI-ассистентов из списка ниже и перечислить их ниже."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b204eb72",
      "metadata": {
        "id": "b204eb72"
      },
      "source": [
        "Список:\n",
        "\n",
        "- [ChatGPT (OpenAI)](https://chatgpt.com/)\n",
        "- [Claude (Anthropic)](https://claude.online/chat)\n",
        "- [Gemini (Google)](https://gemini.google.com/app)\n",
        "- [Grok (xAI)](https://grok.com/)\n",
        "- [Perplexity](https://www.perplexity.ai/)\n",
        "- [DeepSeek](https://chat.deepseek.com/)\n",
        "- [Qwen](https://chat.qwen.ai/)\n",
        "- [Llama (Meta AI)](https://huggingface.co/chat/) c учетной записью от Hugging Face\n",
        "- [Mistral](https://mistral.ai/)\n",
        "- [OpenAssistant](https://open-assistant.io/chat/)\n",
        "- [GigaChat (Sber)](https://giga.chat/#chat)\n",
        "\n",
        "- [Microsoft Copilot](https://copilot.microsoft.com/chats/)\n",
        "- [Tabnine](https://www.tabnine.com/pricing/) - платно, но есть триал\n",
        "- [Amazon Q Developer](https://aws.amazon.com/ru/q/developer/)\n",
        "- [GitHub Copilot](https://github.com/copilot)\n",
        "\n",
        "Вы также можете использовать модели, которые не попали в список, но обязательно указывайте их источник, название и прочие аттрибуты."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62beac30",
      "metadata": {
        "id": "62beac30"
      },
      "source": [
        "DeepSeek (deepThink R1 версия), ChatGPT (4O версия)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1c6e50e",
      "metadata": {
        "id": "a1c6e50e"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0b97a90",
      "metadata": {
        "id": "d0b97a90"
      },
      "source": [
        "## Раздел 2. Написать промпт, отправить AI-ассистентам, сравнить результаты\n",
        "2.1. Написать промпт (желательно один, чтобы можно было корректнее сравнить результат) на любой языке, на котором Вы ожидаете получить лучший результат, в результате которого **выбрать** модель с весами LLM для скачивания (желательно выбирать небольшие модели, чтобы скачивать было не много и матрицы были не слишком большими). Далее будем работать с этой моделью как с матрицей.\n",
        "\n",
        "2.2. Отправить промпт AI-ассистентам, выбранным в разделе 1.\n",
        "\n",
        "2.3. Сравните ответы полученные от разных LLM в таблице.\n",
        "\n",
        "2.4. Выбрать модель для скачивания"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58a51121",
      "metadata": {
        "id": "58a51121"
      },
      "source": [
        "### 2.1 Использованный промпт:\n",
        "\n",
        "List 3–5 open-source LLMs (≤2 B params) for matrix/PCA work. For each, give:\n",
        "- Name, params, download size, license, URL\n",
        "- One-sentence rationale\n",
        "\n",
        "Finally, recommend the single best model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "944e8ddc",
      "metadata": {
        "id": "944e8ddc"
      },
      "source": [
        "### 2.3. Сравнение результатов\n",
        "\n",
        "| **Ассистент** | **Ответ**                                                                                                                                                                                                                                                                                  | **Ваш комментарий**                                                                   |\n",
        "|---|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------|\n",
        "|*DeepSeek (deepThink R1 версия)*| *Microsoft Phi-1.5 is the top choice due to its specialized training on mathematical and coding datasets, MIT license for flexibility, and strong performance in analytical tasks like PCA. Its balance of size (1.3B) and domain relevance makes it uniquely suited for matrix operations.* | *На выбор были: 1. Microsoft Phi-1.5, 2. Pythia-1.4B, 3. TinyLlama-1.1B, 4. Bloom-560M* |\n",
        "|*ChatGPT (4O версия)*| *For tasks involving matrix operations and PCA, GPT-2 is recommended due to its balance between parameter size and performance. It is lightweight, efficient, and capable of assisting in generating code for such tasks.* | *На выбор были: 1. GPT-2, 2. GPT-J 6B, 3. OpenLLaMA 3B*                        |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65dbdf48",
      "metadata": {
        "id": "65dbdf48"
      },
      "source": [
        "### 2.4. Выбранная модель\n",
        "\n",
        "Попробуем взять GPT-2\n",
        "Если в процессе пойдет что-то не так - возьмем Microsoft Phi-1.5 (и почему же гпт рекомендует гпт)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec640cab",
      "metadata": {
        "id": "ec640cab"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9dfe2f28",
      "metadata": {
        "id": "9dfe2f28"
      },
      "source": [
        "## Раздел 3. Скачивание модели с помощью сниппетов от AI-ассистентов\n",
        "С помощью того же или нового набора AI-ассистентов, получите сниппет для скачивания и начала работы с моделью. Вставьте сниппеты в соответствующие ячейки. Запустите ячейки и сравните полученные результаты, не внося дополнительных изменений в код, если он не работает.\n",
        "\n",
        "3.1. Список используемых AI\n",
        "\n",
        "3.2. Сниппеты для скачивания выбранной модели\n",
        "\n",
        "3.3. Запуск сниппетов\n",
        "\n",
        "3.4. Анализ результатов"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5060669",
      "metadata": {
        "id": "e5060669"
      },
      "source": [
        "### 3.1. Список используемых AI\n",
        "\n",
        "DeepSeek (deepThink R1 версия), ChatGPT (4-mini-high) <- поменяла модель на ту, которая лучше дружит с кодированием\n",
        "\n",
        "Промпт:\n",
        "Generate a Python code snippet that demonstrates how to download a GPT-2  model, load it, and use it to process input text, providing an example of how to use the model for inference.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b9967ae",
      "metadata": {
        "id": "7b9967ae"
      },
      "source": [
        "### 3.2. Сниппеты для скачивания выбранной модели"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ca6dc9d",
      "metadata": {
        "id": "6ca6dc9d"
      },
      "source": [
        "Модель 1: DeepSeek"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "30f9aad1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30f9aad1",
        "outputId": "a41f415e-792d-4c2b-d09e-1b2bf711452f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input text: In a world where artificial intelligence\n",
            "Generated text:\n",
            "In a world where artificial intelligence is king, the challenge is to make sure that future generations of researchers don't have to rely on human intelligence to make decisions.\n",
            "\n",
            "For example, in a new study, researchers at the University of California, Santa Cruz, have shown that the human brain can recognize language when a person speaks it.\n",
            "\n",
            "The work, titled \"A more nuanced understanding of how language and cognition evolve in a complex social network,\" was recently published in the journal Frontiers in Neuroscience\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "\n",
        "# Download and load the model and tokenizer\n",
        "model_name = \"gpt2\"  # You can use \"gpt2-medium\", \"gpt2-large\", or \"gpt2-xl\" for larger versions\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "def generate_text(prompt, max_length=50, temperature=0.7, top_k=50):\n",
        "    \"\"\"\n",
        "    Generate text using GPT-2 model\n",
        "    Args:\n",
        "        prompt (str): Input text to start generation\n",
        "        max_length (int): Maximum length of generated text\n",
        "        temperature (float): Controls randomness (lower = more deterministic)\n",
        "        top_k (int): Top-k sampling parameter\n",
        "    Returns:\n",
        "        str: Generated text\n",
        "    \"\"\"\n",
        "    # Tokenize input text\n",
        "    inputs = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "\n",
        "    # Generate text\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            inputs,\n",
        "            max_length=max_length,\n",
        "            temperature=temperature,\n",
        "            top_k=top_k,\n",
        "            pad_token_id=tokenizer.eos_token_id,\n",
        "            do_sample=True,\n",
        "            num_return_sequences=1\n",
        "        )\n",
        "\n",
        "    # Decode and return generated text\n",
        "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return generated_text\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    input_text = \"In a world where artificial intelligence\"\n",
        "    generated = generate_text(input_text, max_length=100)\n",
        "    print(\"Input text:\", input_text)\n",
        "    print(\"Generated text:\")\n",
        "    print(generated)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38dea61d",
      "metadata": {
        "id": "38dea61d"
      },
      "source": [
        "Модель 2: ChatGPT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "36c878d7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538,
          "referenced_widgets": [
            "6e08b036cc044be5ad467d4eaca0dbce",
            "8b62857632314b6eb7686e5e841d2302",
            "0eb3f4bb14fd44b2bf67bbff91aabb7e",
            "3bccf4807ba048df8f6d20576e8e3dd3",
            "aa4e933cb42244e5b19c8dcac8a8e7aa",
            "cecc8268748d4e6e8cb303e6199f49ed",
            "7ef2618fd6834b6eb1264d3f8956f3c7",
            "1984c42c4d33420a9566801034c0b84f",
            "f6a7e6db6e594cfaa825621f6952b694",
            "1e72291944634f77bda8e9796543d06f",
            "200b1a1779ef4855b9b44cc2921206ee",
            "1b3aa4f85de24e48987278ef3e34af5c",
            "4ef28625bf194afbb5d973ea136498c1",
            "2e1dfb9bfd4f4078806641485d78780e",
            "3f506961917242449617c3754f2c1402",
            "98a1bb4c529348c0981b3f753756fe32",
            "8d7887580a5c4d599ef16b26535864f9",
            "96f16b31f67949db8fc8da68731ed31a",
            "9475e16a092c4a14ba7c27812214a253",
            "cbb5a429ac774540b57a6b0278e34a23",
            "b3d8ec7b5ccd48de894bcce28bb3fb4f",
            "28862a72f4b04aabbd9b301b777b38e4",
            "c3265a99b410464ab2a7a388b2639fb6",
            "973729c1b4ac4320b9a3f47adf1e200d",
            "eda0011bc46f410fb1db0187abdcfdbd",
            "30811d5edd434f9b949741d4f2ac8506",
            "c83ee3d7502144fea9e53865b1be9664",
            "e7a7151b06924d28b3534ed60be87d03",
            "824d463454f9423592615f4405b90e61",
            "a535094cd752456bafaa66e43006030a",
            "227caeed58264b5ba9e876c27b5451fc",
            "3baacf44015f42bd8e5d736dca866631",
            "453572e971b14e8aa0868f2319854106",
            "b9a768a6703c434181377b298e580ebc",
            "16a604211a7042ef8d92b6813456ab7f",
            "6c49ec903ce643d5ad7fc828e78bcbea",
            "af094d5e119142289d8794a5b9b40077",
            "a4a1e103a5cd40f08a2fe3f94f4ae97d",
            "8f886e6dbab14572800156f6c1c5ae3c",
            "53ff107a702949108006db589267498a",
            "cbcc417f343446a4ac04d78c70fb1e9d",
            "7246fb1a3f45473f8863a2d869cb1329",
            "11b06ca2cb1a49389513a88bca0bf04e",
            "3b25611c1d9e4fd79a37b9cb4b127cf4",
            "c161d84ab5184c8b936ea019e2f5862c",
            "455ec8e733e6464b8e34aba59b9f9a57",
            "069dc7cf87884f5c9341ac3efbce3cfc",
            "0061138acf714b3a8525f0cea72500fe",
            "dcbe6cde52cf41eeafc2cfb16ec42892",
            "df5ac23a4cac431c9e6b9a97606ab9a6",
            "e278c937c0c945ebbc0551f8ba9a11c5",
            "1eec561865ae48fe9ab809fdfb612460",
            "58951bd02d4e4b40a7e598df48c8933c",
            "e3cc4d6ec4234e7fa8e957f554245a6f",
            "b87702cb69184abc8aa323a865cf9af1",
            "e4815a5538d94e9bbb03e75e1a893c18",
            "647d8f002ea34d0fb77be567a1b6c013",
            "0d7fc11ccc244a079f5eec5c8b23896d",
            "5d67652752d24fe4842dca37c7c24ae7",
            "e7f11779e5e84a8290925b0f7fe94526",
            "b9114f49c2ba4eb3b6118c7ae99ad905",
            "ed754c7dad4a458da014f45cf79e14a7",
            "3e2f9168c26c4f6fb350b1f7e4e0c3ca",
            "31576bc0c2c046c384d521e0e2150cc9",
            "bea3820ecbb045e7b65ef07c4fb142e5",
            "0f0c7dd217ac4f49b45b6051f8721d32",
            "f30a4bc9ae6c41c697b6e817cb8dd47e",
            "7140e9923e3f44f4a69f3b30c31fe43f",
            "318f7eaaa5bb48a4a54999142e66efdc",
            "734bcf01768d4bae9e34119db1c46417",
            "bc2c1fe1384645239545f8c94d649e2d",
            "50d4fb60a33f44e8994c0c2cf114b986",
            "a985949242904b3db7543bd63d737cbf",
            "beb9207a391d4099bcd240a09cf372d0",
            "acee2c75248743bfa01020afb7d3b87c",
            "6ee743dcd14842828a13fbf102e45bd7",
            "5885264f495341cca0c90e10a501c2b5"
          ]
        },
        "id": "36c878d7",
        "outputId": "b25a49b0-88e3-41e7-ee1b-082e4a8c2552"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6e08b036cc044be5ad467d4eaca0dbce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1b3aa4f85de24e48987278ef3e34af5c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c3265a99b410464ab2a7a388b2639fb6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b9a768a6703c434181377b298e580ebc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c161d84ab5184c8b936ea019e2f5862c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e4815a5538d94e9bbb03e75e1a893c18"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f30a4bc9ae6c41c697b6e817cb8dd47e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Text: Once upon a time\n",
            "Generated Text: Once upon a time, the world was a place of great beauty and great danger. The world of the gods was the place where the great gods were born, and where they were to live.\n",
            "\n",
            "The world that was created was not the same as the one that is now. It was an endless, endless world. And the Gods were not born of nothing. They were created of a single, single thing. That was why the universe was so beautiful. Because the cosmos was made of two\n"
          ]
        }
      ],
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "# Load the pre-trained GPT-2 model and tokenizer\n",
        "model_name = 'gpt2'  # You can also use other variants like 'gpt2-medium', 'gpt2-large', or 'gpt2-xl'\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Ensure padding is correctly handled\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Function to generate text based on input\n",
        "def generate_text(prompt, max_length=100):\n",
        "    # Encode the input prompt to tensor\n",
        "    inputs = tokenizer.encode(prompt, return_tensors='pt')\n",
        "\n",
        "    # Generate text with the model\n",
        "    outputs = model.generate(inputs, max_length=max_length, num_return_sequences=1, no_repeat_ngram_size=2)\n",
        "\n",
        "    # Decode the generated text\n",
        "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    return generated_text\n",
        "\n",
        "# Example usage\n",
        "input_text = \"Once upon a time\"\n",
        "generated_text = generate_text(input_text)\n",
        "\n",
        "print(\"Input Text:\", input_text)\n",
        "print(\"Generated Text:\", generated_text)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "201abe2b",
      "metadata": {
        "id": "201abe2b"
      },
      "source": [
        "### 3.4. Анализ результатов\n",
        "\n",
        "Начала с выполнения ячейки от Chat GPT (потому что она сгенерировалась заметно быстрее). DeepSeek долго думал, прежде чем написать код.\n",
        "- Код Chat GPT получился более компактным и более человекочитаемым. На первый згляд он использует больший функционал \"из коробки\", не усложняя выполнение.\n",
        "- DeepSeek добавил больше комментариев к коду (точнее один многострочный комментарий). Получившийся снипет так же сделан с поддержкой импортирования этого скрипта как модуля, что для данной заачи (и работы в Коллабе) выглядит чуть более усложненно.  \n",
        "- Обе предложенные реализации поймаои варнинг, связанный с работой Коллаба (т.к. код при загрузке модели одинаковый) и токенами. Это не очень хорошо, но т.к. в промпте не было уточнений на этот счет - это не страшно."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a34d4af1",
      "metadata": {
        "id": "a34d4af1"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33a780f7",
      "metadata": {
        "id": "33a780f7"
      },
      "source": [
        "## Раздел 4. Первые галлюцинации\n",
        "Если код после запуска не работает, получите у соответствующего AI-ассистента рекомендации по исправлению кода. Вставьте исправленный код в новую соответствующую ячейку. Запустите код и в случае, если код снова не работает, получите новые исправления. Продолжайте либо, пока код не заработает, либо пока AI-ассистент не начнёт слишком сильно галлюцинировать. Протоколируйте все диалоги в соответствующие ячейки. Проведите анализ полученных результатов в текущем разделе.\n",
        "\n",
        "В случае, если все модели отработали безупречно, вернитесь к этому разделу после промта по написанию методов рассчёта собственных значений матрицы (раздел 6) или оптимизации выбранной модели LLM при помощи методов поиска собственных значений и собственных векторов матрицы весов. (раздел 7)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63171b0e",
      "metadata": {
        "id": "63171b0e"
      },
      "source": [
        "#### Справка: Когда LLM начинают галлюцинировать?\n",
        "\n",
        "**LLMs склонны к галлюцинациям во время написания кода, главным образом, в таких ситуациях:**\n",
        "\n",
        "1. **Неоднозначные или недостаточно определенные запросы**  \n",
        "   - Если запрос расплывчатый (\"напишите алгоритм быстрой сортировки\"), то LLM может начать гадать и выдумывать детали.\n",
        "2. **Редкие или незнакомые библиотеки, API или фреймворки**  \n",
        "   - Если Вы спрашиваете о малоизвестном инструменте или совершенно новой версии библиотеки, LLM может \"придумать\" методы, классы или шаблоны использования на основе шаблонов, которые он видел в других местах.\n",
        "3. **Междоменные запросы**  \n",
        "   - При объединении технологий (например, \"использовать модели SQLAlchemy внутри конвейера TensorFlow\") могут возникнуть галлюцинации с API, которых на самом деле не существует.\n",
        "4. **Устаревшие или будущие знания**  \n",
        "   - Если что-то изменилось после завершения обучения модели (например, новые возможности версии Python), она может придумать поведение, которое \"ожидает\", основываясь на тенденциях.\n",
        "5. **Сложные многоэтапные задачи**  \n",
        "   - В более длинных цепочках (например, при полной настройке приложения) накапливаются ошибки - пропущенный импорт, неправильные типы, воображаемые функции и т.д.\n",
        "6. **Когда вас просят оптимизировать, упростить или сильно обобщить**  \n",
        "   - \"Напишите наиболее эффективную систему кэширования\" — это может привести к созданию идеализированных методов, которые звучат правдоподобно, но не являются реальными.\n",
        "7. **Слишком самоуверенные формулировки в запросах**  \n",
        "   - Если вы спросите \"Дайте мне точный вызов API для...\" с полной уверенностью, модель может выдать очень уверенный, но совершенно неверный ответ.\n",
        "\n",
        "**Как распознать галлюцинации, когда LLMs пишут код:**\n",
        "\n",
        "- **Сверьтесь с официальной документацией.**  \n",
        "  Всегда сверяйте названия функций, сигнатуры методов и использование библиотек с реальной документацией.\n",
        "\n",
        "- **Запустите и протестируйте код на ранней стадии.**  \n",
        "  Даже небольшой пример (модульный тест, выполнение скрипта) может сразу выявить недостоверные детали.\n",
        "\n",
        "- **Используйте средства проверки типов и линтеры.**  \n",
        "  Такие инструменты, как \"mypy\", \"pylint\" или \"eslint\", часто обнаруживают (*выдуманные*) ошибочные API, неправильный импорт и т.д.\n",
        "\n",
        "- **Задавайте дополнительные вопросы.**  \n",
        "  Если вы не уверены, вы можете спросить у LLM: \"Вы уверены, что `foo.bar()` существует? Можете ли вы показать документацию?\". Но в последних версиях LLM поголовно научились нагло врать, наставать и выдумывать ссылки.\n",
        "\n",
        "- **Будьте подозрительны к слишком точным ответам.**  \n",
        "  Реальный код часто требует обработки ошибок, нестандартных ситуаций, шагов по настройке. Галлюцинированный код часто выглядит \"слишком чистым\".\n",
        "\n",
        "- **Делайте подсказки конкретными.**  \n",
        "  Сужение задачи снижает вероятность того, что модель ошибется в своих предположениях."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fad8c772",
      "metadata": {
        "id": "fad8c772"
      },
      "source": [
        "Модель 1: Сhat GPT. Фиксим 7 раздел.\n",
        "\n",
        "Пытаюсь понять, оптимизировал он что-то в 7 задании или нет. Новый код по промпту:\n",
        "а ты уверен, что реализовал все требования правильно?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "015fafa0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "015fafa0",
        "outputId": "9872e3e1-4347-4fbc-8ec3-6032c19bcf26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perplexity before PCA optimization: 2.4442\n",
            "Perplexity after PCA optimization: 3.4768\n",
            "PCA Eigenvalues:  [0.0075548  0.0070551  0.00690758 0.00618688 0.00590634 0.00544115\n",
            " 0.00535193 0.00510829 0.00503018 0.0049473  0.00489557 0.00478335\n",
            " 0.00474998 0.00471715 0.0046343  0.00462774 0.00456169 0.00454372\n",
            " 0.00450765 0.00444946 0.00442181 0.00440601 0.00435659 0.00434763\n",
            " 0.00432051 0.00429657 0.00425392 0.00418551 0.00418389 0.00416017\n",
            " 0.00412964 0.00409472 0.00405999 0.0040362  0.00399529 0.00398328\n",
            " 0.00396821 0.00394455 0.00391109 0.00388791 0.00386657 0.00385118\n",
            " 0.00381033 0.00379369 0.00378804 0.00374493 0.00372207 0.00370461\n",
            " 0.00368033 0.00366752 0.00365378 0.00362857 0.0036146  0.00359039\n",
            " 0.00357427 0.00355583 0.00355033 0.00352452 0.00350748 0.00349868\n",
            " 0.00349323 0.0034468  0.00344053 0.00339008 0.00338532 0.00335175\n",
            " 0.00334094 0.00333604 0.00331531 0.00327029 0.00325851 0.00324414\n",
            " 0.00322506 0.00321214 0.00319206 0.00318472 0.00315687 0.00313401\n",
            " 0.00310303 0.0030923  0.00307215 0.00306    0.00304326 0.00302744\n",
            " 0.00300775 0.00299019 0.00298153 0.00297287 0.00295156 0.00294505\n",
            " 0.00293927 0.00292446 0.00290513 0.00289841 0.00287417 0.00286693\n",
            " 0.00284008 0.00283077 0.00281032 0.00279841 0.00277781 0.00277394\n",
            " 0.002753   0.00273737 0.00270341 0.00269344 0.00269025 0.00266948\n",
            " 0.00265414 0.00264418 0.00263373 0.00263142 0.00261567 0.0025965\n",
            " 0.00258269 0.00258066 0.00255857 0.00254462 0.00253631 0.00251397\n",
            " 0.00250894 0.00247906 0.00246766 0.00245659 0.00245107 0.00244511\n",
            " 0.0024209  0.00240786 0.00239511 0.00238933 0.00238635 0.00236574\n",
            " 0.00235869 0.00233659 0.00233546 0.00231918 0.00230768 0.002298\n",
            " 0.00228334 0.00227121 0.00225982 0.00225089 0.00223933 0.00222205\n",
            " 0.00221903 0.00220011 0.00219691 0.00218407 0.00217978 0.00216312\n",
            " 0.00216015 0.00215266 0.0021327  0.00212581 0.00210498 0.00209694\n",
            " 0.00209183 0.00208619 0.00207364 0.00205849 0.00205768 0.00204589\n",
            " 0.0020396  0.00202705 0.00201125 0.0020011  0.00199075 0.0019866\n",
            " 0.00198222 0.00196567 0.00195986 0.00195076 0.00194892 0.00193579\n",
            " 0.00192646 0.00191504 0.00191006 0.00190517 0.00189769 0.0018895\n",
            " 0.00186384 0.001862   0.00185046 0.00184826 0.00184177 0.00184039\n",
            " 0.00183658 0.00182645 0.00182398 0.00181113 0.00180197 0.00179019\n",
            " 0.00178855 0.00177621 0.00177174 0.00176041 0.00175485 0.00174854\n",
            " 0.00173852 0.00172546 0.00171989 0.00171236 0.00170682 0.00170167\n",
            " 0.00169146 0.00168596 0.00167912 0.00166883 0.0016657  0.00166011\n",
            " 0.00165278 0.00164616 0.00163568 0.00163111 0.00161929 0.0016117\n",
            " 0.00160739 0.00160038 0.00159699 0.00158947 0.0015826  0.00157809\n",
            " 0.00157594 0.00156703 0.00155661 0.00155554 0.00154887 0.00154376\n",
            " 0.00153872 0.00153678 0.00153228 0.00152862 0.00152182 0.00151701\n",
            " 0.00150576 0.00149945 0.00148776 0.001487   0.00147771 0.00147605\n",
            " 0.00146765 0.00146117 0.00145529 0.00145364 0.00145176 0.0014446\n",
            " 0.00144193 0.00143718 0.00142822 0.00142577 0.0014185  0.00141551\n",
            " 0.0014081  0.00140052 0.00139503 0.00138975 0.00138618 0.00138346\n",
            " 0.00137776 0.0013703  0.00136632 0.00136143 0.00135934 0.00135207\n",
            " 0.00134536 0.0013439  0.00133766 0.00133342 0.00132832 0.001323\n",
            " 0.00131919 0.0013148  0.00130633 0.00129864 0.00129278 0.00128975\n",
            " 0.00128602 0.00128291 0.00127404 0.0012739  0.00126426 0.00126237\n",
            " 0.00125402 0.00125248 0.00124822 0.00124395 0.00123622 0.00123443\n",
            " 0.00123039 0.0012229  0.00121692 0.00121349 0.00120725 0.00120461\n",
            " 0.00120254 0.001198   0.00119429 0.00118951 0.00118054 0.00117895\n",
            " 0.00117404 0.00116927 0.00116849 0.00116222 0.00115894 0.00115604\n",
            " 0.00115065 0.0011444  0.00114178 0.00114061 0.00113288 0.00112837\n",
            " 0.00112682 0.00112227 0.00111975 0.00111448 0.00110865 0.00110573\n",
            " 0.00110127 0.00109929 0.0010947  0.00109108 0.00108562 0.00108051\n",
            " 0.00107748 0.0010747  0.00107187 0.00106922 0.00106624 0.00106275\n",
            " 0.00105541 0.00105355 0.00105219 0.00104968 0.001044   0.00104273\n",
            " 0.00103462 0.00103321 0.00102515 0.00102032 0.00101764 0.00101381\n",
            " 0.0010096  0.00100768 0.00100493 0.00100332 0.00099986 0.00099775\n",
            " 0.0009943  0.00098729 0.00098522 0.00098474 0.00097864 0.00097254\n",
            " 0.00096727 0.0009645  0.00096102 0.00095691 0.00095455 0.00094856\n",
            " 0.00094712 0.00094215 0.00093358 0.00093199 0.00092927 0.00092684\n",
            " 0.00092418 0.00092285 0.00091771 0.0009167  0.00091582 0.00091103\n",
            " 0.0009065  0.0009022  0.00089915 0.00089793 0.0008946  0.00088991\n",
            " 0.00088841 0.00088655 0.00088246 0.00088051 0.00087323 0.0008714\n",
            " 0.00086782 0.00086536 0.00086247 0.00085902 0.00085721 0.00085265\n",
            " 0.00085024 0.0008484  0.00084567 0.00084129 0.00083634 0.000834\n",
            " 0.00083279 0.00083129 0.0008268  0.00082535 0.00082441 0.00081902\n",
            " 0.00081666 0.0008122  0.00081073 0.00080775 0.00080262 0.00080098\n",
            " 0.00079898 0.00079577 0.00079362 0.00078881 0.00078759 0.000782\n",
            " 0.00077783 0.00077644 0.00077473 0.00077148 0.00076999 0.00076643\n",
            " 0.00075981 0.00075902 0.00075691 0.00075384 0.00075218 0.00075045\n",
            " 0.00074857 0.0007462  0.0007417  0.00074001 0.00073719 0.00073397\n",
            " 0.0007318  0.0007286  0.00072621 0.00072528 0.00072389 0.00072025\n",
            " 0.00071751 0.00071375 0.00071147 0.00070999 0.00070767 0.00070271\n",
            " 0.00070019 0.00069558 0.00069453 0.00068913 0.00068791 0.00068529\n",
            " 0.00068507 0.00067768 0.00067547 0.00067318 0.00067192 0.00066929\n",
            " 0.0006677  0.00066355 0.00066114 0.00065828 0.00065682 0.00065458\n",
            " 0.00065344 0.00064993 0.00064514 0.00064277 0.00064117 0.0006409\n",
            " 0.00063319 0.00063209 0.00063133 0.00063016 0.00062542]\n",
            "PCA Explained Variance (Eigenvalues):  [0.2869553  0.26797512 0.26237175 0.23499723 0.22434162 0.20667206\n",
            " 0.20328334 0.19402903 0.19106238 0.1879143  0.18594931 0.1816868\n",
            " 0.1804194  0.17917249 0.17602539 0.17577636 0.17326753 0.17258509\n",
            " 0.17121494 0.16900457 0.16795422 0.1673543  0.16547717 0.16513692\n",
            " 0.16410677 0.16319737 0.1615773  0.15897906 0.15891756 0.1580163\n",
            " 0.15685675 0.15553036 0.1542113  0.15330777 0.15175393 0.15129767\n",
            " 0.15072508 0.14982651 0.14855558 0.14767513 0.14686464 0.14628021\n",
            " 0.14472859 0.14409639 0.1438819  0.14224446 0.14137603 0.14071299\n",
            " 0.13979046 0.13930409 0.13878213 0.13782467 0.13729385 0.13637449\n",
            " 0.13576198 0.13506179 0.13485298 0.13387261 0.13322516 0.13289115\n",
            " 0.13268411 0.13092057 0.13068223 0.12876618 0.12858535 0.12730992\n",
            " 0.12689948 0.12671341 0.1259259  0.12421598 0.12376866 0.12322256\n",
            " 0.12249798 0.12200738 0.12124464 0.12096587 0.11990776 0.11903981\n",
            " 0.1178631  0.11745548 0.11669014 0.1162286  0.11559266 0.11499189\n",
            " 0.11424383 0.1135768  0.11324786 0.11291891 0.1121095  0.11186228\n",
            " 0.11164269 0.1110803  0.11034597 0.11009063 0.10917015 0.10889503\n",
            " 0.10787525 0.1075215  0.10674487 0.10629263 0.10551002 0.10536315\n",
            " 0.10456771 0.10397408 0.10268407 0.10230532 0.10218413 0.1013954\n",
            " 0.1008125  0.10043435 0.10003754 0.09994982 0.09935155 0.09862338\n",
            " 0.09809873 0.09802181 0.09718262 0.09665285 0.0963371  0.09548873\n",
            " 0.09529734 0.09416271 0.09372951 0.09330916 0.09309958 0.0928729\n",
            " 0.09195329 0.0914581  0.09097387 0.09075426 0.09064122 0.08985826\n",
            " 0.08959052 0.08875093 0.08870836 0.08808982 0.08765299 0.08728537\n",
            " 0.08672842 0.08626791 0.08583509 0.08549594 0.08505677 0.08440063\n",
            " 0.08428598 0.08356711 0.08344574 0.08295808 0.0827948  0.08216198\n",
            " 0.08204938 0.08176504 0.08100682 0.08074514 0.07995391 0.07964844\n",
            " 0.07945418 0.07924007 0.07876351 0.07818788 0.07815737 0.07770949\n",
            " 0.07747065 0.07699386 0.07639384 0.07600828 0.07561483 0.07545741\n",
            " 0.07529113 0.07466228 0.07444169 0.07409622 0.07402617 0.07352752\n",
            " 0.0731729  0.07273944 0.07255024 0.07236455 0.07208022 0.07176908\n",
            " 0.07079455 0.07072472 0.07028639 0.07020294 0.06995614 0.06990381\n",
            " 0.069759   0.06937432 0.06928059 0.06879263 0.06844458 0.06799707\n",
            " 0.06793468 0.06746603 0.0672963  0.06686606 0.0666548  0.06641509\n",
            " 0.06603434 0.06553842 0.06532698 0.06504098 0.06483036 0.06463479\n",
            " 0.06424711 0.06403802 0.06377848 0.06338759 0.06326863 0.06305627\n",
            " 0.06277789 0.06252649 0.0621283  0.0619546  0.06150566 0.06121762\n",
            " 0.06105379 0.06078741 0.06065881 0.06037328 0.0601122  0.05994104\n",
            " 0.05985918 0.05952068 0.05912513 0.05908443 0.05883106 0.05863705\n",
            " 0.05844533 0.05837179 0.05820099 0.05806179 0.05780356 0.05762082\n",
            " 0.05719347 0.05695378 0.05650986 0.05648105 0.0561282  0.05606509\n",
            " 0.05574608 0.05549976 0.05527655 0.05521376 0.05514264 0.05487052\n",
            " 0.05476911 0.05458852 0.05424823 0.05415537 0.05387914 0.05376565\n",
            " 0.05348407 0.05319626 0.05298757 0.05278728 0.05265155 0.05254804\n",
            " 0.05233178 0.05204826 0.05189701 0.05171141 0.05163206 0.05135584\n",
            " 0.05110114 0.05104577 0.05080856 0.05064741 0.0504538  0.05025157\n",
            " 0.0501072  0.04994037 0.04961848 0.04932648 0.04910407 0.04898891\n",
            " 0.04884712 0.04872909 0.04839202 0.04838694 0.04802059 0.047949\n",
            " 0.04763176 0.04757317 0.0474112  0.04724917 0.04695558 0.04688758\n",
            " 0.04673426 0.04644979 0.04622255 0.04609237 0.04585504 0.04575496\n",
            " 0.04567618 0.04550382 0.04536281 0.04518121 0.04484077 0.04478024\n",
            " 0.04459374 0.04441249 0.04438285 0.04414466 0.04402005 0.04390999\n",
            " 0.04370524 0.04346792 0.04336862 0.04332393 0.04303031 0.04285893\n",
            " 0.04280032 0.04262722 0.04253157 0.04233144 0.04211006 0.04199906\n",
            " 0.04182965 0.04175457 0.04158026 0.0414427  0.04123535 0.04104113\n",
            " 0.04092612 0.04082043 0.04071314 0.04061227 0.04049905 0.04036643\n",
            " 0.04008775 0.04001702 0.03996563 0.03987003 0.03965447 0.03960603\n",
            " 0.03929833 0.03924456 0.03893859 0.03875501 0.03865316 0.03850756\n",
            " 0.03834795 0.03827479 0.03817037 0.03810925 0.03797783 0.03789768\n",
            " 0.03776676 0.03750037 0.03742192 0.0374037  0.03717187 0.03693999\n",
            " 0.03673997 0.03663478 0.03650274 0.03634639 0.03625666 0.03602917\n",
            " 0.03597453 0.03578573 0.0354604  0.03539982 0.03529675 0.03520424\n",
            " 0.03510322 0.03505265 0.03485769 0.03481922 0.03478577 0.03460376\n",
            " 0.03443166 0.03426855 0.0341525  0.03410617 0.0339798  0.03380145\n",
            " 0.0337445  0.03367411 0.03351865 0.03344448 0.03316787 0.03309854\n",
            " 0.03296243 0.032869   0.03275943 0.03262842 0.03255946 0.03238637\n",
            " 0.03229476 0.03222478 0.03212126 0.03195485 0.03176702 0.03167786\n",
            " 0.03163199 0.03157494 0.03140439 0.0313496  0.03131387 0.03110881\n",
            " 0.03101939 0.03085002 0.03079416 0.03068086 0.03048617 0.03042372\n",
            " 0.03034787 0.0302258  0.03014436 0.02996138 0.02991508 0.02970302\n",
            " 0.02954442 0.02949167 0.02942657 0.02930334 0.02924655 0.02911135\n",
            " 0.02885984 0.02883003 0.0287497  0.02863313 0.02857001 0.02850444\n",
            " 0.02843313 0.02834305 0.02817219 0.02810784 0.02800086 0.02787863\n",
            " 0.02779624 0.02767469 0.02758372 0.02754843 0.02749552 0.02735752\n",
            " 0.02725329 0.0271105  0.02702399 0.02696785 0.02687973 0.02669134\n",
            " 0.02659559 0.02642042 0.02638043 0.0261752  0.02612908 0.02602961\n",
            " 0.02602102 0.02574052 0.02565633 0.02556967 0.02552151 0.02542182\n",
            " 0.02536133 0.02520356 0.02511232 0.02500347 0.02494794 0.02486319\n",
            " 0.02481972 0.02468647 0.02450445 0.02441445 0.02435374 0.02434345\n",
            " 0.02405069 0.02400862 0.02398004 0.02393534 0.02375536]\n",
            "PCA Components (Eigenvectors):  [[-0.00300465 -0.02028956 -0.00447521 ...  0.00892862 -0.00045475\n",
            "  -0.00431146]\n",
            " [-0.00680489 -0.02467004 -0.01847462 ...  0.01048187 -0.00106256\n",
            "  -0.01651368]\n",
            " [ 0.00170664 -0.01770116  0.00608838 ...  0.02454109  0.0071567\n",
            "   0.00205307]\n",
            " ...\n",
            " [ 0.01498804 -0.02267028  0.00238626 ... -0.01388922 -0.01890685\n",
            "   0.0044501 ]\n",
            " [-0.00857697 -0.00459536  0.02280818 ...  0.02710751  0.00141246\n",
            "  -0.0052195 ]\n",
            " [ 0.00094589 -0.0075021   0.02486718 ...  0.01081795 -0.00129135\n",
            "   0.02052511]]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.nn.functional import log_softmax\n",
        "from math import exp\n",
        "\n",
        "# Load the pre-trained GPT-2 model and tokenizer\n",
        "model_name = 'gpt2'\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Set the padding token to be the EOS token\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Simulate a small dataset (50 examples)\n",
        "class TinyDataset(Dataset):\n",
        "    def __init__(self, tokenizer, num_samples=50):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.num_samples = num_samples\n",
        "        self.examples = [\"Once upon a time\"] * num_samples  # Simplified for the example\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.examples[idx]\n",
        "        encoding = self.tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=50)\n",
        "        return encoding['input_ids'].squeeze(0), encoding['attention_mask'].squeeze(0)\n",
        "\n",
        "# Create a small data loader for testing\n",
        "dataset = TinyDataset(tokenizer)\n",
        "dataloader = DataLoader(dataset, batch_size=5)\n",
        "\n",
        "# Function to compute Perplexity\n",
        "def compute_perplexity(model, dataloader):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    total_tokens = 0\n",
        "    for batch in dataloader:\n",
        "        input_ids, attention_mask = batch\n",
        "        with torch.no_grad():\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=input_ids)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item() * input_ids.size(0)\n",
        "        total_tokens += input_ids.size(0) * input_ids.size(1)\n",
        "\n",
        "    # Compute perplexity\n",
        "    perplexity = exp(total_loss / total_tokens)\n",
        "    return perplexity\n",
        "\n",
        "# Function to apply PCA on the model's weights (in this case, the first transformer layer's weights)\n",
        "def optimize_with_pca(model, n_components=0.9):\n",
        "    pca = PCA(n_components=n_components)\n",
        "\n",
        "    # Apply PCA to all attention layers (Q, K, V) for all transformer layers\n",
        "    for layer in model.transformer.h:\n",
        "        attention_weights = layer.attn.c_attn.weight.detach().cpu().numpy()\n",
        "        reduced_weights = pca.fit_transform(attention_weights)\n",
        "        optimized_weights = pca.inverse_transform(reduced_weights)\n",
        "        layer.attn.c_attn.weight.data = torch.tensor(optimized_weights).to(model.device)\n",
        "\n",
        "    return pca\n",
        "\n",
        "# Evaluate the model's perplexity before optimization\n",
        "initial_perplexity = compute_perplexity(model, dataloader)\n",
        "print(f\"Perplexity before PCA optimization: {initial_perplexity:.4f}\")\n",
        "\n",
        "# Perform PCA optimization on the attention layers\n",
        "pca = optimize_with_pca(model, n_components=0.9)\n",
        "\n",
        "# Evaluate the model's perplexity after optimization\n",
        "optimized_perplexity = compute_perplexity(model, dataloader)\n",
        "print(f\"Perplexity after PCA optimization: {optimized_perplexity:.4f}\")\n",
        "\n",
        "# Print some details about PCA (eigenvalues and components)\n",
        "print(\"PCA Eigenvalues: \", pca.explained_variance_ratio_)\n",
        "print(\"PCA Explained Variance (Eigenvalues): \", pca.explained_variance_)\n",
        "print(\"PCA Components (Eigenvectors): \", pca.components_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Оптимизация стала хуже. Повторная генерация ничего не изменила. Убрала контекст и начала новый чат."
      ],
      "metadata": {
        "id": "1QHH8Yx--rLt"
      },
      "id": "1QHH8Yx--rLt"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "c1223908",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1223908",
        "outputId": "0c9998ab-62e7-4aed-c2e0-84fd0893c3e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy before optimization: 0.00%\n",
            "Applied PCA to embedding layer, reducing dimensions from 768 to 50.\n",
            "Accuracy after optimization: 0.00%\n",
            "Improvement in accuracy: 0.00%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load the GPT-2 model and tokenizer\n",
        "model_name = \"gpt2\"\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Set the pad token to the eos token (end of sequence token)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Example of a small dataset for testing\n",
        "# You can replace this with a real validation set (e.g., Tiny BERTScore dataset)\n",
        "dataset = [\"This is a test sentence.\" for _ in range(50)]  # 50 examples\n",
        "\n",
        "# Function to tokenize the input data and get model outputs\n",
        "def get_model_outputs(texts):\n",
        "    inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
        "    return outputs.logits\n",
        "\n",
        "# Calculate the accuracy of the model's predictions (dummy accuracy for illustration)\n",
        "def compute_accuracy(logits, inputs):\n",
        "    predictions = logits.argmax(dim=-1)\n",
        "    correct = (predictions == inputs[\"input_ids\"]).sum().item()\n",
        "    total = inputs[\"input_ids\"].numel()\n",
        "    return correct / total\n",
        "\n",
        "# PCA Optimization for weight reduction\n",
        "def apply_pca_to_weights(layer_name, n_components=50):\n",
        "    # Extract the embedding layer weights\n",
        "    weights = model.transformer.wte.weight.data.cpu().numpy()  # Embedding weights\n",
        "    original_shape = weights.shape\n",
        "\n",
        "    # Apply PCA for dimensionality reduction\n",
        "    pca = PCA(n_components=n_components)\n",
        "    reduced_weights = pca.fit_transform(weights)\n",
        "    reconstructed_weights = pca.inverse_transform(reduced_weights)\n",
        "\n",
        "    # Replace the original weights with the reconstructed reduced weights\n",
        "    model.transformer.wte.weight.data = torch.tensor(reconstructed_weights, dtype=torch.float32).to(model.device)\n",
        "\n",
        "    print(f\"Applied PCA to {layer_name} layer, reducing dimensions from {original_shape[1]} to {n_components}.\")\n",
        "\n",
        "# Test the model before optimization\n",
        "def test_model_before_optimization():\n",
        "    logits = get_model_outputs(dataset)\n",
        "    accuracy = 0\n",
        "    for i, text in enumerate(dataset):\n",
        "        inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "        accuracy += compute_accuracy(logits[i], inputs)\n",
        "    return accuracy / len(dataset)\n",
        "\n",
        "# Test the model after optimization\n",
        "def test_model_after_optimization():\n",
        "    logits = get_model_outputs(dataset)\n",
        "    accuracy = 0\n",
        "    for i, text in enumerate(dataset):\n",
        "        inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "        accuracy += compute_accuracy(logits[i], inputs)\n",
        "    return accuracy / len(dataset)\n",
        "\n",
        "# Apply PCA and test the optimization\n",
        "def main():\n",
        "    # Test accuracy before optimization\n",
        "    accuracy_before = test_model_before_optimization()\n",
        "    print(f\"Accuracy before optimization: {accuracy_before * 100:.2f}%\")\n",
        "\n",
        "    # Apply PCA to reduce the weights in the embedding layer\n",
        "    apply_pca_to_weights('embedding', n_components=50)\n",
        "\n",
        "    # Test accuracy after optimization\n",
        "    accuracy_after = test_model_after_optimization()\n",
        "    print(f\"Accuracy after optimization: {accuracy_after * 100:.2f}%\")\n",
        "\n",
        "    # Criterion for optimization\n",
        "    improvement = accuracy_after - accuracy_before\n",
        "    print(f\"Improvement in accuracy: {improvement * 100:.2f}%\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "423e8d29",
      "metadata": {
        "id": "423e8d29"
      },
      "source": [
        "Пытаемся указать дополнительно на необходимость использовать TinyBERT"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bert-score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "5E3PmYLxB2W5",
        "outputId": "9026c81b-0de1-4535-fa8f-ab6ccda9dc50"
      },
      "id": "5E3PmYLxB2W5",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bert-score\n",
            "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.6.0+cu124)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.2.2)\n",
            "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from bert-score) (4.51.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.11/dist-packages (from bert-score) (4.67.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from bert-score) (3.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from bert-score) (24.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert-score) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert-score) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert-score) (2025.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.0.0->bert-score)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.0.0->bert-score)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.0.0->bert-score)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.0.0->bert-score)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.0.0->bert-score)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.0.0->bert-score)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.0.0->bert-score)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.0.0->bert-score)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.0.0->bert-score)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.0.0->bert-score)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.0.0->bert-score) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (0.30.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (0.5.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (3.2.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (2025.1.31)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.0.0->bert-score) (3.0.2)\n",
            "Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m84.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bert-score\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed bert-score-0.3.13 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "nvidia"
                ]
              },
              "id": "512cb907fb9e46f2931009d9e6b52b24"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "b31523c1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b31523c1",
        "outputId": "21d9c2b8-1d65-4775-dfe3-29948ef99005"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERTScore до оптимизации: 0.6993\n",
            "Применен PCA к слою embedding, уменьшив размерность с 768 до 50.\n",
            "Собственные значения: [0.21092454 0.09588385 0.08349932 0.08004653 0.07619064 0.07123205\n",
            " 0.06563716 0.06398233 0.0608951  0.05769768 0.05716538 0.05548853\n",
            " 0.05486828 0.05366705 0.05176363 0.05061083 0.04997892 0.04875418\n",
            " 0.04761207 0.04601467 0.04531009 0.04459514 0.04323281 0.04301295\n",
            " 0.04260088 0.0415249  0.041143   0.04046989 0.04004145 0.03978171\n",
            " 0.03909929 0.03864159 0.03806955 0.03756968 0.0373752  0.03702661\n",
            " 0.0369066  0.03678094 0.03623966 0.03618449 0.03561984 0.03527708\n",
            " 0.03497235 0.03470382 0.03437415 0.03423247 0.03397272 0.03388649\n",
            " 0.03356962 0.03338457]\n",
            "Собственные векторы: [[ 1.8414611e-02  2.4681708e-02 -2.1835236e-02 ... -1.7881518e-02\n",
            "  -1.0493988e-02 -4.6813328e-02]\n",
            " [ 1.9506289e-02  9.6143242e-03 -1.5648080e-02 ...  2.2144305e-02\n",
            "  -1.3101786e-02 -1.0279728e-02]\n",
            " [-2.0713249e-02 -1.5950248e-02  7.2769038e-02 ...  3.8263430e-03\n",
            "   2.1643827e-05 -1.9767084e-03]\n",
            " ...\n",
            " [ 2.1323802e-02  2.0817257e-03 -2.0897693e-03 ... -1.0660603e-02\n",
            "  -1.0678928e-03  7.8455377e-03]\n",
            " [ 1.0787173e-02 -8.4363207e-02  1.3589510e-02 ... -2.9735068e-02\n",
            "  -2.6273124e-02  4.5380485e-03]\n",
            " [-9.9935196e-03  1.1207173e-02 -1.5906228e-02 ...  4.0060855e-03\n",
            "  -2.9045224e-02 -9.1642715e-02]]\n",
            "BERTScore после оптимизации: 0.4843\n",
            "Улучшение в BERTScore: -0.2150\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "from sklearn.decomposition import PCA\n",
        "from bert_score import score\n",
        "import transformers\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA as sklearnPCA\n",
        "from huggingface_hub import login\n",
        "\n",
        "# Авторизация на Hugging Face (если требуется доступ к приватным моделям)\n",
        "# login(token='your_token_here')  # Используйте ваш токен, если нужно\n",
        "\n",
        "# Загрузка модели GPT-2 и токенизатора\n",
        "model_name = \"gpt2\"\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Устанавливаем pad_token на eos_token, если он не задан\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Загрузка стандартной модели BERT для BERTScore\n",
        "bert_model_name = 'bert-base-uncased'  # Используем стандартную модель BERT\n",
        "bert_model = transformers.BertModel.from_pretrained(bert_model_name)\n",
        "bert_tokenizer = transformers.BertTokenizer.from_pretrained(bert_model_name)\n",
        "\n",
        "# Пример небольшого набора данных для тестирования\n",
        "dataset = [\"This is a test sentence.\" for _ in range(50)]  # 50 примеров\n",
        "reference = [\"This is a test sentence.\" for _ in range(50)]  # Референсный текст для оценки\n",
        "\n",
        "# Функция для получения выводов модели\n",
        "def get_model_outputs(texts):\n",
        "    inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
        "    return outputs.logits\n",
        "\n",
        "# PCA для оптимизации весов\n",
        "def apply_pca_to_weights(layer_name, n_components=50):\n",
        "    # Извлекаем веса эмбеддинга\n",
        "    weights = model.transformer.wte.weight.data.cpu().numpy()  # Веса эмбеддинга\n",
        "    original_shape = weights.shape\n",
        "\n",
        "    # Применяем PCA для уменьшения размерности\n",
        "    pca = sklearnPCA(n_components=n_components)\n",
        "    reduced_weights = pca.fit_transform(weights)\n",
        "    eigenvalues = pca.explained_variance_\n",
        "    eigenvectors = pca.components_\n",
        "\n",
        "    # Пересчитываем восстановленные веса после PCA\n",
        "    reconstructed_weights = pca.inverse_transform(reduced_weights)\n",
        "\n",
        "    # Заменяем оригинальные веса на уменьшенные\n",
        "    model.transformer.wte.weight.data = torch.tensor(reconstructed_weights, dtype=torch.float32).to(model.device)\n",
        "\n",
        "    print(f\"Применен PCA к слою {layer_name}, уменьшив размерность с {original_shape[1]} до {n_components}.\")\n",
        "    print(f\"Собственные значения: {eigenvalues}\")\n",
        "    print(f\"Собственные векторы: {eigenvectors}\")\n",
        "\n",
        "# Оценка качества модели с использованием BERTScore\n",
        "def evaluate_with_bertscore(model, dataset, reference):\n",
        "    generated_texts = []\n",
        "    for text in dataset:\n",
        "        inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "        outputs = model.generate(inputs[\"input_ids\"], max_length=50, num_return_sequences=1,\n",
        "                                 pad_token_id=tokenizer.eos_token_id, attention_mask=inputs[\"attention_mask\"])\n",
        "        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        generated_texts.append(generated_text)\n",
        "\n",
        "    # Вычисляем BERTScore с использованием стандартной модели BERT\n",
        "    P, R, F1 = score(generated_texts, reference, model_type=bert_model_name)\n",
        "    return torch.mean(F1)  # Применяем torch.mean для корректного вычисления среднего значения\n",
        "\n",
        "# Тестирование модели до оптимизации\n",
        "def test_model_before_optimization():\n",
        "    score_before = evaluate_with_bertscore(model, dataset, reference)\n",
        "    return score_before\n",
        "\n",
        "# Тестирование модели после оптимизации\n",
        "def test_model_after_optimization():\n",
        "    score_after = evaluate_with_bertscore(model, dataset, reference)\n",
        "    return score_after\n",
        "\n",
        "# Основная функция\n",
        "def main():\n",
        "    # Оценка до оптимизации\n",
        "    score_before = test_model_before_optimization()\n",
        "    print(f\"BERTScore до оптимизации: {score_before:.4f}\")\n",
        "\n",
        "    # Применение PCA для уменьшения весов эмбеддинга\n",
        "    apply_pca_to_weights('embedding', n_components=50)\n",
        "\n",
        "    # Оценка после оптимизации\n",
        "    score_after = test_model_after_optimization()\n",
        "    print(f\"BERTScore после оптимизации: {score_after:.4f}\")\n",
        "\n",
        "    # Критерий оптимизации\n",
        "    improvement = score_after - score_before\n",
        "    print(f\"Улучшение в BERTScore: {improvement:.4f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "014b7f6d",
      "metadata": {
        "id": "014b7f6d"
      },
      "source": [
        "Не помогло, оптимизация делает только хуже ("
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a135f37",
      "metadata": {
        "id": "5a135f37"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bcdaff9f",
      "metadata": {
        "id": "bcdaff9f"
      },
      "source": [
        "## Раздел 5. Набросаем код методов самостоятельно из готовой документации\n",
        "\n",
        "Реализуйте расчёт собственных значений матриц весов любого слоя при помощи известных Вам методов самостоятельно, используя стандартные библиотеки Python.\n",
        "\n",
        "Выполните это задание самостоятельно, а не при помощи ассистентов (**любых**, включая GitHub Copilot autocomplite, его можно отключить в настройках справа внизу, Google Colab Gemini тоже можнот отключить в настройках \"Инструменты\"-\"ИИ-функции\"-\"Предлагать подсказки ИИ для дополнения кода\"), чтобы можно было корректно сравнить результаты стандартных библиотек и сниппетов, которые предложат Вам ассистенты далее.\n",
        "\n",
        "\n",
        "| Метод | Функция Python | Библиотека | Ссылка на документацию |\n",
        "|---|---|---|---|\n",
        "|Power Method (Dominant Eigenvalue) | Manual (template provided) | Custom/Numpy | [Tutorial](https://bvanderlei.github.io/jupyter-guide-to-linear-algebra/Approximating_Eigenvalues.html#power-method) or [template](https://en.wikipedia.org/wiki/Power_iteration#Numerical_example) — implement with `numpy.dot` |\n",
        "|Shifted Power Method | Manual + `numpy.linalg.solve` | Numpy | [Tutorial](https://bvanderlei.github.io/jupyter-guide-to-linear-algebra/Approximating_Eigenvalues.html) |\n",
        "|QR Algorithm (Full Spectrum) | `scipy.linalg.eig` or `numpy.linalg.eig` | Scipy/Numpy | [scipy.linalg.eig](https://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.eig.html) / [numpy.linalg.eig](https://numpy.org/doc/stable/reference/generated/numpy.linalg.eig.html) |\n",
        "|Full QR Decomposition (optional deeper understanding) | `numpy.linalg.qr` | Numpy | [numpy.linalg.qr](https://numpy.org/doc/stable/reference/generated/numpy.linalg.qr.html) |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "773b4940",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "773b4940",
        "outputId": "39241547-b6fb-4cdd-8c75-97cd40dcd9c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eigenvalues: [5. 2.]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "A = np.array([[4, 1], [2, 3]])\n",
        "\n",
        "def qr_algorithm(A, num_iterations=1000):\n",
        "    A_copy = A.copy()\n",
        "    for _ in range(num_iterations):\n",
        "        Q, R = np.linalg.qr(A_copy)\n",
        "        A_copy = np.dot(R, Q)\n",
        "    return np.diagonal(A_copy)\n",
        "\n",
        "\n",
        "eig = qr_algorithm(A)\n",
        "print(f\"Eigenvalues: {eig}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d17fb7e",
      "metadata": {
        "id": "9d17fb7e"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b22ec577",
      "metadata": {
        "id": "b22ec577"
      },
      "source": [
        "## Раздел 6. AI-ассистенты пишут код для расчёта собственных значений и векторов матриц\n",
        "6.1. Напишите промпт для получения сниппетов методов расчёта собственных значений и векторов матриц.\n",
        "\n",
        "6.2. Сниппеты для расчёта собственных значений и векторов матриц\n",
        "\n",
        "6.3. Запуск сниппетов против любой выбранной Вами матрицы\n",
        "\n",
        "6.4. Анализ результатов"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c178daa2",
      "metadata": {
        "id": "c178daa2"
      },
      "source": [
        "### 6.1 Ваш промпт\n",
        "\n",
        "Provide Python code snippets for calculating eigenvalues and eigenvectors of the matrix A: A = ([[4, 1], [2, 3]])\n",
        "Please include the necessary imports and how to use each method with the given matrix A."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0dadb9ce",
      "metadata": {
        "id": "0dadb9ce"
      },
      "source": [
        "### 6.2. Сниппеты для расчёта собственных значений и векторов матриц"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "677cf1f0",
      "metadata": {
        "id": "677cf1f0"
      },
      "source": [
        "Модель 1: DeepSeek"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a12c1217",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a12c1217",
        "outputId": "e8db80ea-6327-485b-c800-0cbefd6ab72f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eigenvalues: [5. 2.]\n",
            "Eigenvector for 5.00: [0.70710678 0.70710678]\n",
            "Eigenvector for 2.00: [ 0.4472136  -0.89442719]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "A = np.array([[4, 1],\n",
        "              [2, 3]])\n",
        "\n",
        "# Find eigenvalues via characteristic equation\n",
        "trace = np.trace(A)\n",
        "det = np.linalg.det(A)\n",
        "eigenvalues = np.roots([1, -trace, det])\n",
        "\n",
        "print(\"Eigenvalues:\", eigenvalues)\n",
        "\n",
        "# Find eigenvectors manually\n",
        "for λ in eigenvalues:\n",
        "    B = A - λ * np.eye(2)\n",
        "    _, _, vh = np.linalg.svd(B)\n",
        "    eigenvector = vh[-1]\n",
        "    print(f\"Eigenvector for {λ:.2f}: {eigenvector}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f91e330f",
      "metadata": {
        "id": "f91e330f"
      },
      "source": [
        "Модель 2: ChatGPT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "189121a9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "189121a9",
        "outputId": "17f90ed7-32f0-4f06-f8ba-bd29442111b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eigenvalues:\n",
            "[5. 2.]\n",
            "\n",
            "Eigenvectors:\n",
            "[[ 0.70710678 -0.4472136 ]\n",
            " [ 0.70710678  0.89442719]]\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "\n",
        "# Define the matrix A\n",
        "A = np.array([[4, 1], [2, 3]])\n",
        "\n",
        "# Calculate eigenvalues and eigenvectors\n",
        "eigenvalues, eigenvectors = np.linalg.eig(A)\n",
        "\n",
        "# Print the results\n",
        "print(\"Eigenvalues:\")\n",
        "print(eigenvalues)\n",
        "\n",
        "print(\"\\nEigenvectors:\")\n",
        "print(eigenvectors)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7f50616",
      "metadata": {
        "id": "d7f50616"
      },
      "source": [
        "### 6.3. Запуск сниппетов на любой выбранной матрице и численное сравнение с вашей реализацией"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "38af45ba",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38af45ba",
        "outputId": "15063b3f-63eb-44fe-e77d-9d5276c8bf52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Мой код - Собственные значения:\n",
            "[7. 4.]\n",
            "\n",
            "Код дипсика - Собственные значения и векторы:\n",
            "Eigenvalues: [7. 4.]\n",
            "Eigenvectors: [array([0.89442719, 0.4472136 ]), array([ 0.70710678, -0.70710678])]\n",
            "\n",
            "Код GPT - Собственные значения и векторы:\n",
            "Eigenvalues: [7. 4.]\n",
            "Eigenvectors: [[ 0.89442719 -0.70710678]\n",
            " [ 0.4472136   0.70710678]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "A = np.array([[6, 2], [1, 5]])\n",
        "\n",
        "# Мой код\n",
        "def qr_algorithm(A, num_iterations=1000):\n",
        "    A_copy = A.copy()\n",
        "    for _ in range(num_iterations):\n",
        "        Q, R = np.linalg.qr(A_copy)\n",
        "        A_copy = np.dot(R, Q)\n",
        "    return np.diagonal(A_copy)\n",
        "\n",
        "# Код DeepSeek\n",
        "def dipstick_method(A):\n",
        "    trace = np.trace(A)\n",
        "    det = np.linalg.det(A)\n",
        "    eigenvalues = np.roots([1, -trace, det])\n",
        "\n",
        "    eigenvectors = []\n",
        "    for λ in eigenvalues:\n",
        "        B = A - λ * np.eye(2)\n",
        "        _, _, vh = np.linalg.svd(B)\n",
        "        eigenvector = vh[-1]\n",
        "        eigenvectors.append(eigenvector)\n",
        "\n",
        "    return eigenvalues, eigenvectors\n",
        "\n",
        "# Код Chat GPT\n",
        "def gpt_method(A):\n",
        "    eigenvalues, eigenvectors = np.linalg.eig(A)\n",
        "    return eigenvalues, eigenvectors\n",
        "\n",
        "\n",
        "print(\"Мой код - Собственные значения:\")\n",
        "eig_qr = qr_algorithm(A)\n",
        "print(eig_qr)\n",
        "\n",
        "print(\"\\nКод дипсика - Собственные значения и векторы:\")\n",
        "eigenvalues_dip, eigenvectors_dip = dipstick_method(A)\n",
        "print(\"Eigenvalues:\", eigenvalues_dip)\n",
        "print(\"Eigenvectors:\", eigenvectors_dip)\n",
        "\n",
        "print(\"\\nКод GPT - Собственные значения и векторы:\")\n",
        "eigenvalues_gpt, eigenvectors_gpt = gpt_method(A)\n",
        "print(\"Eigenvalues:\", eigenvalues_gpt)\n",
        "print(\"Eigenvectors:\", eigenvectors_gpt)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65965f46",
      "metadata": {
        "id": "65965f46"
      },
      "source": [
        "### 6.4. Анализ полученных результатов\n",
        "\n",
        "|Модель|Комментарий|\n",
        "|---|---|\n",
        "|Me, myself and I| Изобретаем велосипед, проверяем только собственные значения|\n",
        "|DeepSeek| Знак для собственного вектора отличается от результата GPT, для векторов это нормально.|\n",
        "|Chat GRT| Быстро, красиво, в одну строку, \"из коробки\". Т.к. код маленький и простой - не возникает проблем с ошибками компиляции.|\n",
        "\n",
        "В итоге получились верные, работающий крограммы (с точностью до знака векторов, но это не является ошибкой). При этом DeepSeek выдал сразу несколько решений, что не требовалось в промпте. GPT при этом ограничилось одним решением, как и запрашивалось."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60c4e1c5",
      "metadata": {
        "id": "60c4e1c5"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a9de463",
      "metadata": {
        "id": "8a9de463"
      },
      "source": [
        "## Раздел 7. Оптимизация LLM при помощи метода главных компонент"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9f1846a",
      "metadata": {
        "id": "c9f1846a"
      },
      "source": [
        "### Справка: Метод главных компонент простыми словами с акцентом на собственные числа и собственные векторы\n",
        "\n",
        "**Определение**\n",
        "\n",
        "Метод главных компонентов (PCA - Principal Component Analysis) это подход к уменьшению размерности, такой что:\n",
        "1. Находит новые оси (основные компоненты), где данные отличаются больше всего.\n",
        "2. Проецирует данные на меньшее количество измерений, сохраняя при этом максимальную дисперсию.\n",
        "\n",
        "**Как это работает с позиции собсвенных чисел и векторов:**\n",
        "1. Берем матрицу данных `X` (например, включения токенов или скрытые слои LLM).\n",
        "2. Вычисляем ковариационную матрицу:  \n",
        "   $$\n",
        "   C = \\frac{1}{n} X^T X\n",
        "   $$\n",
        "3. Находим собственные числа и собственные векторы ковариационной матрицы`C`.\n",
        "   - *Собственные векторы* = направления (главные компоненты)\n",
        "   - *Собственные числа* = величина отклонения (дисперсии), зафиксированная в каждом направлении\n",
        "4. Выберем только *топ-k собственных векторов* (наибольшие собственные числа) → получим сокращённое число измерений.\n",
        "\n",
        "**Значение метода главных компонент для оптимизации размера LLM**\n",
        "\n",
        "1. Сжатия слоев встраивания (embedding kayers) или скрытых представлений\n",
        "- Пример: Вы сокращаете 768-мерные встраивания BERT до 128D, используя 128 лучших собственных векторов → огромная экономия памяти.\n",
        "- Полезно для **дистилляции**, **квантования** или **работе на устройстве**.\n",
        "\n",
        "2. Удалить избыточность в пространствах внимания (attention matrix)/фичах (Feature spaces)\n",
        "- Заголовки внимания часто имеют \"низкоуровневую структуру\" (например, всего несколько доминирующих собственных мод).\n",
        "- PCA может выявлять и \"сокращать\" или объединять заголовки, которые обладают сходными характеристиками.\n",
        "\n",
        "3. Проанализировать репрезентативную способность\n",
        "Построение собственного значения **спектра** скрытых состояний говорит вам:\n",
        "- Насколько выразительная часть модели сосредоточена всего в нескольких направлениях.\n",
        "- Является ли результат работы слоя **низкоуровневым** (сжимаемым).\n",
        "\n",
        "\n",
        "### Визуальное представление\n",
        "- **Плоская кривая собственных значений** → разнообразные, высокоуровневые представления (сложнее сжимать).\n",
        "- **Крутой спад собственных значений** → большая часть информации сосредоточена в нескольких направлениях (легко сжимается с помощью PCA).\n",
        "\n",
        "### Реальное приложение:\n",
        "Google, Meta и HuggingFace использовали PCA и **низкоуровневую аппроксимацию** (например, усеченный SVD, линейные узкие места) для:\n",
        "  - Сжатия моделей для мобильного развертывания.\n",
        "  - Ускорения вывода.\n",
        "  - Понять, на что модель \"обращает внимание\".\n",
        "\n",
        "\n",
        "\n",
        "**PCA использует собственные значения/векторы ковариационной матрицы для определения доминирующих направлений в данных. В LLMs PCA выявляет избыточную структуру и обеспечивает сжатие путем проецирования вложений/выходных данных в подпространство меньшей размерности, что делает модели более быстрыми и компактными без существенной потери точности.**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8658d43",
      "metadata": {
        "id": "c8658d43"
      },
      "source": [
        "7.1. Протокол запросов к выбранному (одному) ассистенту. Вы должны убедить его предоставить вам код оптимизации модели LLM (с которой Вы начинали работать в разделах 3-4), использующий метод главных компонентов с акцентом на использование методов расчёта собственных значений и собсвенных векторов. Также необходимо протестировать точность до и после оптимизации при помощи сокращённого набора данных (например, Tiny BERTScore (50 примеров)). Для оптимизации слой можно использовать любой, какой выберете или какой насоветует AI. Не обязательно сокращать все слои.\n",
        "\n",
        "7.2. Полученный в результате код (обновляете в процессе работы над этим разделом, можно оставить только то, что получится в итоге)\n",
        "\n",
        "7.3. Анализ трудностей и галлюцинаций на этом этапе. Как вы с этим справлялись (выявляли и исправляли).\n",
        "\n",
        "7.4. Анализ полученной оптимизированной модели и применения метода"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f2afffc",
      "metadata": {
        "id": "4f2afffc"
      },
      "source": [
        "### 7.1. Протокол запросов к выбранному ассистенту.\n",
        "\n",
        "Укажите, какой выбрали в итоге AI-ассистент. Приведите список промптов, которые вы пробовали.\n",
        "\n",
        "Chat GPT (4o-mini-high)\n",
        "\n",
        "**Промпт 1**:\n",
        "Provide Python code for optimizing an LLM model using Principal Component Analysis (PCA), focusing on the use of eigenvalue and eigenvector computation methods. The code should:\n",
        "1. Include PCA implementation for dimensionality reduction of the model's weights (you can choose the layer to optimize or suggest one based on your knowledge).\n",
        "2. Apply eigenvalue and eigenvector computations during the optimization process.\n",
        "3. Test the model's accuracy before and after optimization using a reduced dataset (e.g., Tiny BERTScore with 50 examples).\n",
        "4. Include any necessary imports, setup, and details for testing accuracy.\n",
        "\n",
        "Please suggest a layer to optimize if unsure.\n",
        "\n",
        "**Промпт 2** (для исправления ошибки): ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.\n",
        "\n",
        "**Промпт 3**: Проанализируй вывод кода (он прикреплен выше). Ты точно добился оптимизации?\n",
        "**Промтп 4**: Perplexity before PCA optimization: 2.4442, Perplexity after PCA optimization: 3.4768. Оптимизация не удалась, перегенерируй код."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d20106e",
      "metadata": {
        "id": "8d20106e"
      },
      "source": [
        "### 7.2. Полученный код (в результате совместной работы и доработок):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "e5b2f9e8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5b2f9e8",
        "outputId": "d2a43812-7306-4a99-eb8f-df414e00c873"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy before PCA optimization: 0.0000\n",
            "Accuracy after PCA optimization: 0.0000\n",
            "PCA Eigenvalues:  [0.02843004 0.02320209 0.02218907 0.01118033 0.00919784 0.00784012\n",
            " 0.00700603 0.00694292 0.00678673 0.00674207 0.00664981 0.00647773\n",
            " 0.00645821 0.00633618 0.0061688  0.00610498 0.00610272 0.00595685\n",
            " 0.00594769 0.00588136 0.00585627 0.00580269 0.00571554 0.00567108\n",
            " 0.00556388 0.00551927 0.00548839 0.00542392 0.00539786 0.00529561\n",
            " 0.00528494 0.00525929 0.00521568 0.00521015 0.00507888 0.00501852\n",
            " 0.0049875  0.00492477 0.00490224 0.00485763 0.00476582 0.00473946\n",
            " 0.00466688 0.00462832 0.00454606 0.00450011 0.00446194 0.00435948\n",
            " 0.00431916 0.00428984 0.00421963 0.00420975 0.00418572 0.00410201\n",
            " 0.00401405 0.00397065 0.00389099 0.00386044 0.00383655 0.00375145\n",
            " 0.00371842 0.00370128 0.0036226  0.00356542 0.00354041 0.00347301\n",
            " 0.00335772 0.00334709 0.00327665 0.00325667 0.00321002 0.00320394\n",
            " 0.00318656 0.00312843 0.00309987 0.00304752 0.00302162 0.0030065\n",
            " 0.00298803 0.00296248 0.00291354 0.00289093 0.00288185 0.00286656\n",
            " 0.00283432 0.00281067 0.0027955  0.00277457 0.00272421 0.00272038\n",
            " 0.00268951 0.00267979 0.00265959 0.0026522  0.00263298 0.00262423\n",
            " 0.00260651 0.00259618 0.00257127 0.00254604 0.00253123 0.00250281\n",
            " 0.00248949 0.00248267 0.00247969 0.00245322 0.00243995 0.00241767\n",
            " 0.00240821 0.00237979 0.00237446 0.00234801 0.0023423  0.00233494\n",
            " 0.00231249 0.00230971 0.00228761 0.00227076 0.00225502 0.00224659\n",
            " 0.00224437 0.00222245 0.0022158  0.00220546 0.00220049 0.00218582\n",
            " 0.00216555 0.00216016 0.00215275 0.00213366 0.00212984 0.00212138\n",
            " 0.00211487 0.0020938  0.0020801  0.00207655 0.0020664  0.00205118\n",
            " 0.00204228 0.00203678 0.00201862 0.00200815 0.00200311 0.00199566\n",
            " 0.00198778 0.00198172 0.00196596 0.00195005 0.00193959 0.00192648\n",
            " 0.00192337 0.00191375 0.00190003 0.00189193 0.00188589 0.00186965\n",
            " 0.00186574 0.00185489 0.00184663 0.00184176 0.00183106 0.00182447\n",
            " 0.00180462 0.00179569 0.0017923  0.00177644 0.00177155 0.00176382\n",
            " 0.00175587 0.00175337 0.00174432 0.00173824 0.00173406 0.00172432\n",
            " 0.00170309 0.00169857 0.00168644 0.00168208 0.00167123 0.00166429\n",
            " 0.00166084 0.00165254 0.00165079 0.00164349 0.00163627 0.00163069\n",
            " 0.00161941 0.00161251 0.00160545 0.00160237 0.0015942  0.0015879\n",
            " 0.00157881 0.00157125 0.00155966 0.0015534  0.001548   0.00154112\n",
            " 0.00152473 0.0015211  0.00151887 0.00151243 0.00150583 0.00149475\n",
            " 0.00149098 0.00148322 0.00147179 0.00146829 0.00146109 0.00145708\n",
            " 0.00145121 0.00144323 0.00143756 0.00142828 0.00142482 0.0014197\n",
            " 0.00140978 0.00140925 0.00139739 0.00139027 0.00138519 0.00138327\n",
            " 0.00137739 0.00136376 0.00136174 0.00135948 0.00135607 0.00134977\n",
            " 0.00134733 0.00133469 0.00132815 0.00132044 0.00131435 0.00130783\n",
            " 0.00130086 0.00129319 0.00129009 0.00128066 0.00127852 0.00127592\n",
            " 0.0012724  0.00126548 0.00125862 0.00125361 0.00125086 0.00124383\n",
            " 0.0012403  0.00123389 0.00122472 0.00122163 0.00121155 0.00120737\n",
            " 0.00119816 0.00119587 0.00119385 0.0011872  0.00118351 0.00117695\n",
            " 0.00117047 0.00116574 0.00116445 0.00115672 0.00115526 0.0011476\n",
            " 0.00113833 0.00113806 0.00113221 0.00112906 0.0011261  0.00111885\n",
            " 0.00111403 0.0011112  0.00110531 0.00110387 0.00109814 0.00109177\n",
            " 0.00108603 0.0010794  0.00107138 0.00107035 0.0010682  0.00105908\n",
            " 0.00105531 0.0010517  0.00104762 0.00104257 0.00103838 0.00103142\n",
            " 0.00102653 0.00102354 0.00101905 0.00101485 0.00100667 0.00100116\n",
            " 0.0009999  0.00099331 0.00098947 0.00098588 0.00098129 0.00097836\n",
            " 0.00097338 0.00096841 0.00096702 0.0009609  0.00095846 0.00095315\n",
            " 0.00095156 0.00094724 0.00094459 0.00093681 0.00093613 0.0009331\n",
            " 0.00092483 0.000922   0.00091996 0.00091757 0.00090876 0.00090714\n",
            " 0.00090341 0.00089962 0.00089927 0.00088967 0.00088521 0.0008847\n",
            " 0.00087764 0.00087571 0.00087153 0.00086263 0.00085967 0.00085844\n",
            " 0.00085156 0.00084515 0.00084456 0.00084045 0.00083817 0.00083401\n",
            " 0.00082829 0.00082479 0.00082235 0.00082026 0.00081701 0.00081173\n",
            " 0.00080946 0.00080441 0.00080278 0.00079567 0.00079188 0.00078883\n",
            " 0.0007856  0.00078355 0.00078261 0.00077342 0.00076953 0.00076786\n",
            " 0.00076387 0.00076249 0.00076077 0.0007585  0.00075393 0.00074952\n",
            " 0.00074537 0.00074103 0.00073997 0.00073408 0.00073357 0.00072915\n",
            " 0.00072631 0.00072233 0.00071706 0.00071479 0.00071423 0.00071013\n",
            " 0.00070506 0.00070302 0.00069762 0.00069354 0.00068997 0.00068619\n",
            " 0.00068485 0.00068141 0.00068042 0.00067829 0.00067192 0.00067017\n",
            " 0.00066796 0.00066145 0.00066004 0.00065898 0.00065683 0.00065423\n",
            " 0.00064951 0.00064661 0.00064012 0.0006393  0.0006364  0.00063115\n",
            " 0.00062796 0.00062385 0.00062216]\n",
            "PCA Explained Variance (Eigenvalues):  [2.6088798  2.1291373  2.0361772  1.0259615  0.8440386  0.71944773\n",
            " 0.6429078  0.63711673 0.6227835  0.61868507 0.6102189  0.59442776\n",
            " 0.5926373  0.5814389  0.56607956 0.5602232  0.5600153  0.54663014\n",
            " 0.54578936 0.53970224 0.5373999  0.53248286 0.5244862  0.52040625\n",
            " 0.5105685  0.506475   0.5036414  0.49772546 0.49533394 0.4859513\n",
            " 0.4849722  0.48261836 0.47861654 0.47810912 0.46606317 0.46052364\n",
            " 0.45767784 0.4519207  0.44985324 0.4457602  0.43733504 0.43491647\n",
            " 0.428256   0.42471772 0.41716915 0.41295174 0.4094491  0.400047\n",
            " 0.3963471  0.3936569  0.38721344 0.3863075  0.3841024  0.37642068\n",
            " 0.36834875 0.36436632 0.3570559  0.35425323 0.3520604  0.34425113\n",
            " 0.34122083 0.3396478  0.33242786 0.32718006 0.32488546 0.3187005\n",
            " 0.30812111 0.30714574 0.3006819  0.29884827 0.29456756 0.29400954\n",
            " 0.29241437 0.28707984 0.28445894 0.2796555  0.27727872 0.27589095\n",
            " 0.2741959  0.27185166 0.26736107 0.26528567 0.26445308 0.2630495\n",
            " 0.2600909  0.2579207  0.2565285  0.25460824 0.24998668 0.24963498\n",
            " 0.24680248 0.24591057 0.24405721 0.2433785  0.2416154  0.24081177\n",
            " 0.23918575 0.23823857 0.23595199 0.23363669 0.23227848 0.22967023\n",
            " 0.2284477  0.22782226 0.22754814 0.2251197  0.22390205 0.22185726\n",
            " 0.22098881 0.21838136 0.21789248 0.2154648  0.21494097 0.21426588\n",
            " 0.21220548 0.21195039 0.20992234 0.20837587 0.20693155 0.20615782\n",
            " 0.205954   0.20394291 0.20333277 0.20238347 0.20192786 0.20058112\n",
            " 0.1987213  0.1982268  0.19754718 0.19579539 0.19544473 0.19466823\n",
            " 0.19407077 0.19213761 0.19088058 0.19055466 0.18962264 0.18822637\n",
            " 0.18740916 0.18690456 0.1852385  0.1842778  0.18381532 0.18313158\n",
            " 0.18240875 0.1818524  0.18040635 0.17894654 0.17798613 0.17678279\n",
            " 0.17649798 0.17561485 0.17435588 0.17361318 0.17305867 0.17156832\n",
            " 0.17120922 0.17021392 0.16945599 0.16900909 0.16802688 0.16742197\n",
            " 0.16560088 0.16478147 0.16447051 0.16301483 0.16256581 0.16185647\n",
            " 0.16112696 0.16089797 0.16006774 0.15950951 0.15912618 0.15823221\n",
            " 0.156284   0.15586902 0.1547563  0.15435556 0.15336041 0.15272352\n",
            " 0.15240699 0.15164548 0.15148453 0.1508145  0.15015173 0.1496397\n",
            " 0.14860491 0.14797172 0.14732395 0.14704153 0.1462917  0.14571331\n",
            " 0.14487958 0.14418572 0.14312233 0.14254774 0.14205244 0.14142068\n",
            " 0.13991694 0.1395837  0.13937905 0.13878807 0.13818242 0.13716555\n",
            " 0.13681917 0.13610786 0.1350591  0.13473722 0.13407654 0.13370898\n",
            " 0.13317016 0.1324378  0.1319173  0.13106552 0.13074806 0.13027821\n",
            " 0.12936832 0.12931956 0.12823135 0.12757777 0.12711188 0.12693597\n",
            " 0.12639621 0.12514532 0.12495995 0.12475208 0.12443982 0.12386186\n",
            " 0.12363721 0.12247773 0.12187764 0.12116978 0.12061081 0.12001279\n",
            " 0.11937309 0.11866935 0.11838517 0.11751992 0.11732334 0.11708461\n",
            " 0.11676128 0.11612689 0.11549678 0.11503734 0.11478517 0.11414018\n",
            " 0.11381619 0.113228   0.11238609 0.11210229 0.1111777  0.11079387\n",
            " 0.10994917 0.10973892 0.10955318 0.10894357 0.1086043  0.10800283\n",
            " 0.10740846 0.1069737  0.10685545 0.1061461  0.10601275 0.10530977\n",
            " 0.10445879 0.10443429 0.10389757 0.10360789 0.10333632 0.10267085\n",
            " 0.10222846 0.10196899 0.10142832 0.10129687 0.10077059 0.10018574\n",
            " 0.09965963 0.09905086 0.09831549 0.09822076 0.09802321 0.09718597\n",
            " 0.0968405  0.09650887 0.09613495 0.09567166 0.09528703 0.09464852\n",
            " 0.09419896 0.09392539 0.09351292 0.09312745 0.09237664 0.09187095\n",
            " 0.09175538 0.09115124 0.0907983  0.09046903 0.09004752 0.08977909\n",
            " 0.08932243 0.08886591 0.08873832 0.08817731 0.08795341 0.08746531\n",
            " 0.08731996 0.08692297 0.08668049 0.08596589 0.08590363 0.08562608\n",
            " 0.0848666  0.08460682 0.08442017 0.08420037 0.0833926  0.08324379\n",
            " 0.08290131 0.08255385 0.08252165 0.0816406  0.08123153 0.08118398\n",
            " 0.08053623 0.08035952 0.07997627 0.0791592  0.0788879  0.07877509\n",
            " 0.07814316 0.07755466 0.07750092 0.07712425 0.07691477 0.07653274\n",
            " 0.07600769 0.07568658 0.07546327 0.07527066 0.07497305 0.07448816\n",
            " 0.07427977 0.07381693 0.0736669  0.07301416 0.07266647 0.07238706\n",
            " 0.07209031 0.07190192 0.07181578 0.07097248 0.07061563 0.07046249\n",
            " 0.07009657 0.06997023 0.06981207 0.06960354 0.06918435 0.06877928\n",
            " 0.06839862 0.0680002  0.06790315 0.06736314 0.06731597 0.06690995\n",
            " 0.06665001 0.06628451 0.06580137 0.06559285 0.06554157 0.06516477\n",
            " 0.06469995 0.06451295 0.06401667 0.06364301 0.06331491 0.06296825\n",
            " 0.06284488 0.06252994 0.06243848 0.06224329 0.06165824 0.06149827\n",
            " 0.06129515 0.06069807 0.06056857 0.06047078 0.06027389 0.06003501\n",
            " 0.05960245 0.0593363  0.05874052 0.05866495 0.05839917 0.05791713\n",
            " 0.05762455 0.05724761 0.05709222]\n",
            "PCA Components (Eigenvectors):  [[-7.3652612e-03 -2.4339973e-03 -1.0733289e-02 ... -6.7786349e-04\n",
            "  -1.0353740e-03 -6.7249959e-04]\n",
            " [-1.6452461e-02 -1.6880745e-02 -2.9364587e-03 ...  1.3687914e-03\n",
            "  -6.3486688e-04  1.0525063e-03]\n",
            " [ 5.4000462e-03 -1.7501079e-03  2.7572063e-03 ...  4.6685804e-04\n",
            "  -8.0726843e-04 -2.3488450e-05]\n",
            " ...\n",
            " [ 1.8047372e-02  1.2919256e-03  1.5211603e-02 ...  1.3737276e-02\n",
            "  -4.3530152e-03  1.0739256e-02]\n",
            " [-6.3322604e-02 -5.3013958e-02 -4.7678865e-02 ...  5.8186725e-03\n",
            "   1.8678593e-02  1.3295095e-02]\n",
            " [-8.0514029e-02  2.1615466e-02  6.8397075e-03 ...  1.2374313e-02\n",
            "  -2.4006476e-03  2.7714707e-03]]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import random\n",
        "\n",
        "# Load the pre-trained GPT-2 model and tokenizer\n",
        "model_name = 'gpt2'\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Set the padding token to be the EOS token\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Simulate a small dataset (50 examples)\n",
        "class TinyDataset(Dataset):\n",
        "    def __init__(self, tokenizer, num_samples=50):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.num_samples = num_samples\n",
        "        self.examples = [\"Once upon a time\"] * num_samples  # Simplified for the example\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.examples[idx]\n",
        "        encoding = self.tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=50)\n",
        "        return encoding['input_ids'].squeeze(0), encoding['attention_mask'].squeeze(0)\n",
        "\n",
        "# Create a small data loader for testing\n",
        "dataset = TinyDataset(tokenizer)\n",
        "dataloader = DataLoader(dataset, batch_size=5)\n",
        "\n",
        "# Function to evaluate model accuracy (simplified for illustration purposes)\n",
        "def evaluate_model(model, dataloader):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    targets = []\n",
        "    for batch in dataloader:\n",
        "        input_ids, attention_mask = batch\n",
        "        with torch.no_grad():\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=input_ids)\n",
        "        logits = outputs.logits\n",
        "        preds = torch.argmax(logits, dim=-1)\n",
        "        predictions.append(preds)\n",
        "        targets.append(input_ids)\n",
        "\n",
        "    # Flatten predictions and targets\n",
        "    predictions = torch.cat(predictions).numpy()\n",
        "    targets = torch.cat(targets).numpy()\n",
        "\n",
        "    # Compute accuracy (simplified as token-wise comparison)\n",
        "    accuracy = accuracy_score(targets.flatten(), predictions.flatten())\n",
        "    return accuracy\n",
        "\n",
        "# Function to apply PCA on the model's weights (in this case, the first transformer layer's weights)\n",
        "def optimize_with_pca(model, layer_idx=0, n_components=0.9):\n",
        "    # Extract the weights of the chosen layer (first transformer layer, hidden states)\n",
        "    layer = model.transformer.h[layer_idx]\n",
        "\n",
        "    # Get the weights of the attention layers (Q, K, V) and the linear layers\n",
        "    attention_weights = layer.attn.c_attn.weight.detach().cpu().numpy()\n",
        "\n",
        "    # Apply PCA on the attention weights\n",
        "    pca = PCA(n_components=n_components)\n",
        "    reduced_weights = pca.fit_transform(attention_weights)\n",
        "\n",
        "    # Reconstruct the weights with reduced components\n",
        "    optimized_weights = pca.inverse_transform(reduced_weights)\n",
        "\n",
        "    # Set the optimized weights back to the model\n",
        "    model.transformer.h[layer_idx].attn.c_attn.weight.data = torch.tensor(optimized_weights).to(model.device)\n",
        "\n",
        "    # Return the PCA object for inspecting eigenvalues and eigenvectors\n",
        "    return pca\n",
        "\n",
        "# Evaluate the model's performance before optimization\n",
        "initial_accuracy = evaluate_model(model, dataloader)\n",
        "print(f\"Accuracy before PCA optimization: {initial_accuracy:.4f}\")\n",
        "\n",
        "# Perform PCA optimization on the first transformer layer\n",
        "pca = optimize_with_pca(model, layer_idx=0, n_components=0.9)\n",
        "\n",
        "# Evaluate the model's performance after optimization\n",
        "optimized_accuracy = evaluate_model(model, dataloader)\n",
        "print(f\"Accuracy after PCA optimization: {optimized_accuracy:.4f}\")\n",
        "\n",
        "# Print some details about PCA (eigenvalues and components)\n",
        "print(\"PCA Eigenvalues: \", pca.explained_variance_ratio_)\n",
        "print(\"PCA Explained Variance (Eigenvalues): \", pca.explained_variance_)\n",
        "print(\"PCA Components (Eigenvectors): \", pca.components_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1a97514",
      "metadata": {
        "id": "b1a97514"
      },
      "source": [
        "### 7.3. Анализ трудностей и галлюцинаций на этом этапе. Как вы с этим справлялись (выявляли и исправляли).\n",
        "\n",
        "Вообще я начинала с DeepSeek, но сервер занят. Это считается галлюцинацией?\n",
        "\n",
        "Сгенерированный гпт первый код ошибся с токенайзером для GPT-2. Похоже, что из-за особенностей модели, пэддинг токен отстутсвует. Возможно, GPT поетрял контекст или не изпользовал предыдущий написанный код и ошибся в генерации. После передачи прямого текста ошибки гпт исправил код на работоспособный, с использованием eos_token.\n",
        "\n",
        "Попробовала уточнить. есть ли оптимизация, т.к. судя по выводу оптимизации не было достигнуто в принципе. Дальнейшие мучения в разделе 4.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f69f14f",
      "metadata": {
        "id": "0f69f14f"
      },
      "source": [
        "### 7.4. Анализ полученной оптимизированной модели и применения метода\n",
        "\n",
        "Оптимизировался только первый слой, однако судя по выводу оптимизации не получилось (я пыталась, но видимо или в промпте ошибка, или я не совсем понимаю, куда его надо подтолкнуть, что бы код показывал оптимизацию). Финальным кодом можно считать тот, котрый находится в ячеке раздела 7, т.к. поптки исправить галлюцинации привели или к улучшению, или не изминили ничего (коды в разделе 4)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45712c46",
      "metadata": {
        "id": "45712c46"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f734eb5d",
      "metadata": {
        "id": "f734eb5d"
      },
      "source": [
        "Что хочется добавить к сегодняшнему занятию:\n",
        "\n",
        "1. [Код](https://github.com/tongjingqi/MathTrap) со ссылкой на статью про математические ловушки для LLM\n",
        "\n",
        "2. [Заметка](https://habr.com/ru/articles/904754/) о том, какие навыки *кажется следует* подтягивать программистам в современной индустрии\n",
        "\n",
        "3. Работая с различными AI-ассистентами, по крайней мере в Университете, будьте готовы к тому, что Вы не сможете получить максимум баллов за выполненные с их помощью работы, если только в задании не требуется обратное. Я провела опрос среди преподавателей нашего факультета (участие приняли 30 человек). 50% преподавателей высказались о том, что не поставят максимальный балл за работу выполненную с помощью GPT и аналогов, предлагая урезать баллы минимум в половину. Ещё 30% процентов поставят 0 баллов за такую работу и только лишь 20% преподавателей согласны принять работу выполненную при помощи ИИ-агентов и оценивать как выполненную самостоятельно."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02a847da",
      "metadata": {
        "id": "02a847da"
      },
      "source": [
        "## Итог\n",
        "\n",
        "Расскажите о Вашем сегодняшнем опыте: если это привычный способ изучения новой области, прототипирования, то на сколько удалось погрузиться в тему собственных чисел и оптимизации LLM. Если вообще все Вам показалось новым, включая общение с LLM, то расскажите, как Вы справлись с написанием промптов и кода? Если писали пропты на языке отличном от родного, то на сколько трудно это Вам показалось и какие подходы использовали (например, машинный перевод?)\n",
        "- Погружение в собственные числа и LLM прошло успешно, но я предпочитаю в таких случаях скорее искать через LLM объяснения алгоритмов и какую-то иинформацию со ссылками на источники, а не готовый код. Поэтому написание большого кода доставило достаточно много неприятностей.\n",
        "- Мне особенно понравился \"сервер занят\" от DeepSeek. Про промпты: на английском в целом нормально получилось, но т.к. уточнения для модели я писала на русском - пояснения модели выдавали на русском.\n",
        "\n",
        "Как Вы сами оцениваете свой прогресс на сегодняшнем занятии?\n",
        "- Сегодня получились промпты получше. Мой навык их написания повысился.\n",
        "\n",
        "Удалось ли Вам изучить всё то, что перечисленно в самом первом списке в ноутбуке? Что вызвало наибольшее затруднение?\n",
        "- Удалос. Трудности: получение от AI действительно рабочего результата с учетом достаточно большого количества мелких ошибок, устранение галлюцинаций в коде; оптимизация моделей доставила немного боли."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6e08b036cc044be5ad467d4eaca0dbce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8b62857632314b6eb7686e5e841d2302",
              "IPY_MODEL_0eb3f4bb14fd44b2bf67bbff91aabb7e",
              "IPY_MODEL_3bccf4807ba048df8f6d20576e8e3dd3"
            ],
            "layout": "IPY_MODEL_aa4e933cb42244e5b19c8dcac8a8e7aa"
          }
        },
        "8b62857632314b6eb7686e5e841d2302": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cecc8268748d4e6e8cb303e6199f49ed",
            "placeholder": "​",
            "style": "IPY_MODEL_7ef2618fd6834b6eb1264d3f8956f3c7",
            "value": "config.json: 100%"
          }
        },
        "0eb3f4bb14fd44b2bf67bbff91aabb7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1984c42c4d33420a9566801034c0b84f",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f6a7e6db6e594cfaa825621f6952b694",
            "value": 665
          }
        },
        "3bccf4807ba048df8f6d20576e8e3dd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e72291944634f77bda8e9796543d06f",
            "placeholder": "​",
            "style": "IPY_MODEL_200b1a1779ef4855b9b44cc2921206ee",
            "value": " 665/665 [00:00&lt;00:00, 13.7kB/s]"
          }
        },
        "aa4e933cb42244e5b19c8dcac8a8e7aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cecc8268748d4e6e8cb303e6199f49ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ef2618fd6834b6eb1264d3f8956f3c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1984c42c4d33420a9566801034c0b84f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6a7e6db6e594cfaa825621f6952b694": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1e72291944634f77bda8e9796543d06f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "200b1a1779ef4855b9b44cc2921206ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b3aa4f85de24e48987278ef3e34af5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4ef28625bf194afbb5d973ea136498c1",
              "IPY_MODEL_2e1dfb9bfd4f4078806641485d78780e",
              "IPY_MODEL_3f506961917242449617c3754f2c1402"
            ],
            "layout": "IPY_MODEL_98a1bb4c529348c0981b3f753756fe32"
          }
        },
        "4ef28625bf194afbb5d973ea136498c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d7887580a5c4d599ef16b26535864f9",
            "placeholder": "​",
            "style": "IPY_MODEL_96f16b31f67949db8fc8da68731ed31a",
            "value": "model.safetensors: 100%"
          }
        },
        "2e1dfb9bfd4f4078806641485d78780e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9475e16a092c4a14ba7c27812214a253",
            "max": 548105171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cbb5a429ac774540b57a6b0278e34a23",
            "value": 548105171
          }
        },
        "3f506961917242449617c3754f2c1402": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3d8ec7b5ccd48de894bcce28bb3fb4f",
            "placeholder": "​",
            "style": "IPY_MODEL_28862a72f4b04aabbd9b301b777b38e4",
            "value": " 548M/548M [00:06&lt;00:00, 98.4MB/s]"
          }
        },
        "98a1bb4c529348c0981b3f753756fe32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d7887580a5c4d599ef16b26535864f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96f16b31f67949db8fc8da68731ed31a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9475e16a092c4a14ba7c27812214a253": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbb5a429ac774540b57a6b0278e34a23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b3d8ec7b5ccd48de894bcce28bb3fb4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28862a72f4b04aabbd9b301b777b38e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3265a99b410464ab2a7a388b2639fb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_973729c1b4ac4320b9a3f47adf1e200d",
              "IPY_MODEL_eda0011bc46f410fb1db0187abdcfdbd",
              "IPY_MODEL_30811d5edd434f9b949741d4f2ac8506"
            ],
            "layout": "IPY_MODEL_c83ee3d7502144fea9e53865b1be9664"
          }
        },
        "973729c1b4ac4320b9a3f47adf1e200d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7a7151b06924d28b3534ed60be87d03",
            "placeholder": "​",
            "style": "IPY_MODEL_824d463454f9423592615f4405b90e61",
            "value": "generation_config.json: 100%"
          }
        },
        "eda0011bc46f410fb1db0187abdcfdbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a535094cd752456bafaa66e43006030a",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_227caeed58264b5ba9e876c27b5451fc",
            "value": 124
          }
        },
        "30811d5edd434f9b949741d4f2ac8506": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3baacf44015f42bd8e5d736dca866631",
            "placeholder": "​",
            "style": "IPY_MODEL_453572e971b14e8aa0868f2319854106",
            "value": " 124/124 [00:00&lt;00:00, 8.93kB/s]"
          }
        },
        "c83ee3d7502144fea9e53865b1be9664": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7a7151b06924d28b3534ed60be87d03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "824d463454f9423592615f4405b90e61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a535094cd752456bafaa66e43006030a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "227caeed58264b5ba9e876c27b5451fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3baacf44015f42bd8e5d736dca866631": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "453572e971b14e8aa0868f2319854106": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9a768a6703c434181377b298e580ebc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_16a604211a7042ef8d92b6813456ab7f",
              "IPY_MODEL_6c49ec903ce643d5ad7fc828e78bcbea",
              "IPY_MODEL_af094d5e119142289d8794a5b9b40077"
            ],
            "layout": "IPY_MODEL_a4a1e103a5cd40f08a2fe3f94f4ae97d"
          }
        },
        "16a604211a7042ef8d92b6813456ab7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f886e6dbab14572800156f6c1c5ae3c",
            "placeholder": "​",
            "style": "IPY_MODEL_53ff107a702949108006db589267498a",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "6c49ec903ce643d5ad7fc828e78bcbea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbcc417f343446a4ac04d78c70fb1e9d",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7246fb1a3f45473f8863a2d869cb1329",
            "value": 26
          }
        },
        "af094d5e119142289d8794a5b9b40077": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11b06ca2cb1a49389513a88bca0bf04e",
            "placeholder": "​",
            "style": "IPY_MODEL_3b25611c1d9e4fd79a37b9cb4b127cf4",
            "value": " 26.0/26.0 [00:00&lt;00:00, 451B/s]"
          }
        },
        "a4a1e103a5cd40f08a2fe3f94f4ae97d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f886e6dbab14572800156f6c1c5ae3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53ff107a702949108006db589267498a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cbcc417f343446a4ac04d78c70fb1e9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7246fb1a3f45473f8863a2d869cb1329": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "11b06ca2cb1a49389513a88bca0bf04e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b25611c1d9e4fd79a37b9cb4b127cf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c161d84ab5184c8b936ea019e2f5862c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_455ec8e733e6464b8e34aba59b9f9a57",
              "IPY_MODEL_069dc7cf87884f5c9341ac3efbce3cfc",
              "IPY_MODEL_0061138acf714b3a8525f0cea72500fe"
            ],
            "layout": "IPY_MODEL_dcbe6cde52cf41eeafc2cfb16ec42892"
          }
        },
        "455ec8e733e6464b8e34aba59b9f9a57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df5ac23a4cac431c9e6b9a97606ab9a6",
            "placeholder": "​",
            "style": "IPY_MODEL_e278c937c0c945ebbc0551f8ba9a11c5",
            "value": "vocab.json: 100%"
          }
        },
        "069dc7cf87884f5c9341ac3efbce3cfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1eec561865ae48fe9ab809fdfb612460",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_58951bd02d4e4b40a7e598df48c8933c",
            "value": 1042301
          }
        },
        "0061138acf714b3a8525f0cea72500fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3cc4d6ec4234e7fa8e957f554245a6f",
            "placeholder": "​",
            "style": "IPY_MODEL_b87702cb69184abc8aa323a865cf9af1",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 4.23MB/s]"
          }
        },
        "dcbe6cde52cf41eeafc2cfb16ec42892": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df5ac23a4cac431c9e6b9a97606ab9a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e278c937c0c945ebbc0551f8ba9a11c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1eec561865ae48fe9ab809fdfb612460": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58951bd02d4e4b40a7e598df48c8933c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e3cc4d6ec4234e7fa8e957f554245a6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b87702cb69184abc8aa323a865cf9af1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e4815a5538d94e9bbb03e75e1a893c18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_647d8f002ea34d0fb77be567a1b6c013",
              "IPY_MODEL_0d7fc11ccc244a079f5eec5c8b23896d",
              "IPY_MODEL_5d67652752d24fe4842dca37c7c24ae7"
            ],
            "layout": "IPY_MODEL_e7f11779e5e84a8290925b0f7fe94526"
          }
        },
        "647d8f002ea34d0fb77be567a1b6c013": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9114f49c2ba4eb3b6118c7ae99ad905",
            "placeholder": "​",
            "style": "IPY_MODEL_ed754c7dad4a458da014f45cf79e14a7",
            "value": "merges.txt: 100%"
          }
        },
        "0d7fc11ccc244a079f5eec5c8b23896d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e2f9168c26c4f6fb350b1f7e4e0c3ca",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_31576bc0c2c046c384d521e0e2150cc9",
            "value": 456318
          }
        },
        "5d67652752d24fe4842dca37c7c24ae7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bea3820ecbb045e7b65ef07c4fb142e5",
            "placeholder": "​",
            "style": "IPY_MODEL_0f0c7dd217ac4f49b45b6051f8721d32",
            "value": " 456k/456k [00:00&lt;00:00, 2.84MB/s]"
          }
        },
        "e7f11779e5e84a8290925b0f7fe94526": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9114f49c2ba4eb3b6118c7ae99ad905": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed754c7dad4a458da014f45cf79e14a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e2f9168c26c4f6fb350b1f7e4e0c3ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31576bc0c2c046c384d521e0e2150cc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bea3820ecbb045e7b65ef07c4fb142e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f0c7dd217ac4f49b45b6051f8721d32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f30a4bc9ae6c41c697b6e817cb8dd47e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7140e9923e3f44f4a69f3b30c31fe43f",
              "IPY_MODEL_318f7eaaa5bb48a4a54999142e66efdc",
              "IPY_MODEL_734bcf01768d4bae9e34119db1c46417"
            ],
            "layout": "IPY_MODEL_bc2c1fe1384645239545f8c94d649e2d"
          }
        },
        "7140e9923e3f44f4a69f3b30c31fe43f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50d4fb60a33f44e8994c0c2cf114b986",
            "placeholder": "​",
            "style": "IPY_MODEL_a985949242904b3db7543bd63d737cbf",
            "value": "tokenizer.json: 100%"
          }
        },
        "318f7eaaa5bb48a4a54999142e66efdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_beb9207a391d4099bcd240a09cf372d0",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_acee2c75248743bfa01020afb7d3b87c",
            "value": 1355256
          }
        },
        "734bcf01768d4bae9e34119db1c46417": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ee743dcd14842828a13fbf102e45bd7",
            "placeholder": "​",
            "style": "IPY_MODEL_5885264f495341cca0c90e10a501c2b5",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 5.42MB/s]"
          }
        },
        "bc2c1fe1384645239545f8c94d649e2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50d4fb60a33f44e8994c0c2cf114b986": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a985949242904b3db7543bd63d737cbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "beb9207a391d4099bcd240a09cf372d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "acee2c75248743bfa01020afb7d3b87c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6ee743dcd14842828a13fbf102e45bd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5885264f495341cca0c90e10a501c2b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}